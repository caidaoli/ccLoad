package main

import (
	"context"
	"database/sql"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/bytedance/sonic"
	_ "modernc.org/sqlite"
)

type SQLiteStore struct {
	db        *sql.DB
	redisSync *RedisSync // RedisåŒæ­¥å®¢æˆ·ç«¯ (OCP: å¼€æ”¾æ‰©å±•ï¼Œå°é—­ä¿®æ”¹)
	stmtCache sync.Map   // é¢„ç¼–è¯‘è¯­å¥ç¼“å­˜ (æ€§èƒ½ä¼˜åŒ–: å‡å°‘SQLè§£æå¼€é”€20-30%)
	stmtMux   sync.Mutex // ä¿æŠ¤é¢„ç¼–è¯‘è¯­å¥åˆ›å»ºè¿‡ç¨‹

	// å¼‚æ­¥RedisåŒæ­¥æœºåˆ¶ï¼ˆæ€§èƒ½ä¼˜åŒ–: é¿å…åŒæ­¥ç­‰å¾…ï¼‰
	syncCh chan struct{} // åŒæ­¥è§¦å‘ä¿¡å·ï¼ˆæ— ç¼“å†²ï¼Œå»é‡åˆå¹¶å¤šä¸ªè¯·æ±‚ï¼‰
	done   chan struct{} // ä¼˜é›…å…³é—­ä¿¡å·
}

// maskAPIKey å°†API Keyæ©ç ä¸º "abcd...klmn" æ ¼å¼ï¼ˆå‰4ä½ + ... + å4ä½ï¼‰
func maskAPIKey(key string) string {
	if len(key) <= 8 {
		return key // çŸ­keyç›´æ¥è¿”å›
	}
	return key[:4] + "..." + key[len(key)-4:]
}

func NewSQLiteStore(path string, redisSync *RedisSync) (*SQLiteStore, error) {
	if err := os.MkdirAll(filepath.Dir(path), 0o755); err != nil {
		return nil, err
	}
	// ä¿®å¤æ—¶åŒºé—®é¢˜ï¼šå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ—¶åŒºè§£ææ—¶é—´æˆ³ï¼Œé¿å…UTC/æœ¬åœ°æ—¶åŒºæ··æ·†å¯¼è‡´å†·å´æ—¶é—´è®¡ç®—é”™è¯¯
	dsn := fmt.Sprintf("file:%s?_pragma=busy_timeout(5000)&_foreign_keys=on&_pragma=journal_mode=WAL&_loc=Local", path)
	db, err := sql.Open("sqlite", dsn)
	if err != nil {
		return nil, err
	}
	db.SetMaxOpenConns(25)
	db.SetMaxIdleConns(5)
	db.SetConnMaxLifetime(5 * time.Minute)

	s := &SQLiteStore{
		db:        db,
		redisSync: redisSync,
		syncCh:    make(chan struct{}, 1), // ç¼“å†²åŒº=1ï¼Œå…è®¸ä¸€ä¸ªå¾…å¤„ç†ä»»åŠ¡
		done:      make(chan struct{}),
	}

	if err := s.migrate(context.Background()); err != nil {
		_ = db.Close()
		return nil, err
	}

	// å¯åŠ¨å¼‚æ­¥RedisåŒæ­¥workerï¼ˆä»…å½“Rediså¯ç”¨æ—¶ï¼‰
	if redisSync != nil && redisSync.IsEnabled() {
		go s.redisSyncWorker()
	}

	// æ€§èƒ½ä¼˜åŒ–ï¼šé¢„ç¼–è¯‘æ‰€æœ‰çƒ­æŸ¥è¯¢ï¼ˆé˜¶æ®µ1ä¼˜åŒ–ï¼‰
	if err := s.prepareAllHotQueries(context.Background()); err != nil {
		// é¢„ç¼–è¯‘å¤±è´¥ä¸å½±å“å¯åŠ¨ï¼Œä»…è®°å½•è­¦å‘Š
		fmt.Printf("è­¦å‘Šï¼šé¢„ç¼–è¯‘çƒ­æŸ¥è¯¢å¤±è´¥: %v\n", err)
	}

	return s, nil
}

// migrate åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ï¼ˆUnixæ—¶é—´æˆ³åŸç”Ÿæ”¯æŒï¼‰
func (s *SQLiteStore) migrate(ctx context.Context) error {
	// åˆ›å»º channels è¡¨ï¼ˆcreated_at/updated_atä½¿ç”¨BIGINT Unixç§’æ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS channels (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			NAME TEXT NOT NULL,
			api_key TEXT NOT NULL,
			url TEXT NOT NULL,
			priority INTEGER NOT NULL DEFAULT 0,
			models TEXT NOT NULL,
			enabled INTEGER NOT NULL DEFAULT 1,
			created_at BIGINT NOT NULL,
			updated_at BIGINT NOT NULL
		);
	`); err != nil {
		return fmt.Errorf("create channels table: %w", err)
	}

	// åˆ›å»º cooldowns è¡¨ï¼ˆä½¿ç”¨Unixæ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS cooldowns (
			channel_id INTEGER PRIMARY KEY,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create cooldowns table: %w", err)
	}

	// åˆ›å»º logs è¡¨ï¼ˆtimeä½¿ç”¨BIGINT Unixæ¯«ç§’æ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS logs (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			TIME BIGINT NOT NULL,
			model TEXT,
			channel_id INTEGER,
			status_code INTEGER NOT NULL,
			message TEXT,
			duration REAL,
			is_streaming INTEGER NOT NULL DEFAULT 0,
			first_byte_time REAL,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE SET NULL
		);
	`); err != nil {
		return fmt.Errorf("create logs table: %w", err)
	}

	// æ·»åŠ æ–°å­—æ®µï¼ˆå…¼å®¹å·²æœ‰æ•°æ®åº“ï¼‰
	s.addColumnIfNotExists(ctx, "logs", "is_streaming", "INTEGER NOT NULL DEFAULT 0")
	s.addColumnIfNotExists(ctx, "logs", "first_byte_time", "REAL")
	s.addColumnIfNotExists(ctx, "logs", "api_key_used", "TEXT")                          // ä½¿ç”¨çš„API Keyï¼ˆå®Œæ•´å€¼ï¼‰
	s.addColumnIfNotExists(ctx, "channels", "model_redirects", "TEXT DEFAULT '{}'")      // æ¨¡å‹é‡å®šå‘å­—æ®µï¼ŒJSONæ ¼å¼
	s.addColumnIfNotExists(ctx, "channels", "api_keys", "TEXT DEFAULT '[]'")             // å¤šKeyæ”¯æŒï¼ŒJSONæ•°ç»„
	s.addColumnIfNotExists(ctx, "channels", "key_strategy", "TEXT DEFAULT 'sequential'") // Keyä½¿ç”¨ç­–ç•¥
	s.addColumnIfNotExists(ctx, "channels", "channel_type", "TEXT DEFAULT 'anthropic'")  // æ¸ é“ç±»å‹

	// åˆ›å»º key_cooldowns è¡¨ï¼ˆKeyçº§åˆ«å†·å´ï¼Œä½¿ç”¨Unixæ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS key_cooldowns (
			channel_id INTEGER NOT NULL,
			key_index INTEGER NOT NULL,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			PRIMARY KEY(channel_id, key_index),
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create key_cooldowns table: %w", err)
	}

	// åˆ›å»º key_rr è¡¨ï¼ˆKeyçº§åˆ«è½®è¯¢æŒ‡é’ˆï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS key_rr (
			channel_id INTEGER PRIMARY KEY,
			idx INTEGER NOT NULL,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create key_rr table: %w", err)
	}

	// åˆ›å»º rr (round-robin) è¡¨
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS rr (
			KEY TEXT PRIMARY KEY,
			idx INTEGER NOT NULL
		);
	`); err != nil {
		return fmt.Errorf("create rr table: %w", err)
	}

	// åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_logs_time ON logs(TIME);
	`); err != nil {
		return fmt.Errorf("create logs time index: %w", err)
	}

	// åˆ›å»ºæ¸ é“åç§°ç´¢å¼•
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_channels_name ON channels(NAME);
	`); err != nil {
		return fmt.Errorf("create channels name index: %w", err)
	}

	// åˆ›å»ºæ—¥å¿—çŠ¶æ€ç ç´¢å¼•
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_logs_status ON logs(status_code);
	`); err != nil {
		return fmt.Errorf("create logs status index: %w", err)
	}

	// æ€§èƒ½ä¼˜åŒ–ï¼šåˆ›å»ºå¤åˆç´¢å¼•ä¼˜åŒ–å¸¸è§æŸ¥è¯¢ï¼ˆé˜¶æ®µ1ä¼˜åŒ–ï¼‰
	// idx_logs_time_model - ä¼˜åŒ–æŒ‰æ—¶é—´+æ¨¡å‹æŸ¥è¯¢ï¼ˆstatsã€metricsæ¥å£ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_logs_time_model ON logs(time, model);
	`); err != nil {
		return fmt.Errorf("create logs time_model index: %w", err)
	}

	// idx_logs_time_channel - ä¼˜åŒ–æŒ‰æ—¶é—´+æ¸ é“æŸ¥è¯¢ï¼ˆmetricsæ¥å£æ¸ é“åˆ†ç»„ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_logs_time_channel ON logs(time, channel_id);
	`); err != nil {
		return fmt.Errorf("create logs time_channel index: %w", err)
	}

	// idx_logs_time_status - ä¼˜åŒ–æŒ‰æ—¶é—´+çŠ¶æ€ç æŸ¥è¯¢ï¼ˆé”™è¯¯æ—¥å¿—è¿‡æ»¤ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_logs_time_status ON logs(time, status_code);
	`); err != nil {
		return fmt.Errorf("create logs time_status index: %w", err)
	}

	// ç¡®ä¿channelsè¡¨çš„nameå­—æ®µå…·æœ‰UNIQUEçº¦æŸ
	if err := s.ensureChannelNameUnique(ctx); err != nil {
		return fmt.Errorf("ensure channel name unique: %w", err)
	}

	// è¿ç§»api_keyså­—æ®µï¼šä¿®å¤å†å²æ•°æ®ä¸­çš„"null"å­—ç¬¦ä¸²é—®é¢˜
	if err := s.migrateAPIKeysField(ctx); err != nil {
		return fmt.Errorf("migrate api_keys field: %w", err)
	}

	// è¿ç§»å†·å´è¡¨çš„untilå­—æ®µä»TIMESTAMPåˆ°Unixæ—¶é—´æˆ³
	if err := s.migrateCooldownToUnixTimestamp(ctx); err != nil {
		return fmt.Errorf("migrate cooldown to unix timestamp: %w", err)
	}

	// Unixæ—¶é—´æˆ³é‡æ„ï¼šé‡å»ºè¡¨ç»“æ„ï¼ˆTIMESTAMP â†’ BIGINTï¼‰
	if err := s.rebuildLogsTableToUnixTimestamp(ctx); err != nil {
		return fmt.Errorf("rebuild logs table: %w", err)
	}
	if err := s.rebuildChannelsTableToUnixTimestamp(ctx); err != nil {
		return fmt.Errorf("rebuild channels table: %w", err)
	}

	return nil
}

// addColumnIfNotExists æ·»åŠ åˆ—å¦‚æœä¸å­˜åœ¨ï¼ˆç”¨äºæ•°æ®åº“å‡çº§å…¼å®¹ï¼‰
func (s *SQLiteStore) addColumnIfNotExists(ctx context.Context, tableName, columnName, columnDef string) {
	// æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
	query := fmt.Sprintf("PRAGMA table_info(%s)", tableName)
	rows, err := s.db.QueryContext(ctx, query)
	if err != nil {
		return
	}
	defer rows.Close()

	exists := false
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, pk int
		var dfltValue sql.NullString

		if err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == columnName {
			exists = true
			break
		}
	}

	if !exists {
		alterQuery := fmt.Sprintf("ALTER TABLE %s ADD COLUMN %s %s", tableName, columnName, columnDef)
		s.db.ExecContext(ctx, alterQuery)
	}
}

// migrateAPIKeysField æ•°æ®åº“è¿ç§»ï¼šä¿®å¤api_keyså­—æ®µçš„è„æ•°æ®
// é—®é¢˜ï¼šå†å²æ•°æ®ä¸­api_keyså¯èƒ½å­˜å‚¨ä¸º"null"å­—ç¬¦ä¸²ï¼Œå¯¼è‡´GetAPIKeys()è¿”å›ç©ºæ•°ç»„
// è§£å†³æ–¹æ¡ˆï¼šå°†api_keyå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰è½¬æ¢ä¸ºapi_keys JSONæ•°ç»„
// æ‰§è¡Œæ—¶æœºï¼šæœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œï¼ˆåœ¨ensureChannelNameUniqueä¹‹åï¼‰
func (s *SQLiteStore) migrateAPIKeysField(ctx context.Context) error {
	// æŸ¥è¯¢æ‰€æœ‰éœ€è¦è¿ç§»çš„æ¸ é“ï¼šapi_keysä¸º"null"æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œä½†api_keyä¸ä¸ºç©º
	rows, err := s.db.QueryContext(ctx, `
		SELECT id, api_key
		FROM channels
		WHERE (api_keys IS NULL OR api_keys = 'null' OR api_keys = '' OR api_keys = '[]')
		  AND api_key IS NOT NULL
		  AND api_key != ''
	`)
	if err != nil {
		return fmt.Errorf("query channels for migration: %w", err)
	}
	defer rows.Close()

	migratedCount := 0
	for rows.Next() {
		var id int64
		var apiKey string
		if err := rows.Scan(&id, &apiKey); err != nil {
			continue // è·³è¿‡é”™è¯¯è¡Œ
		}

		// ä½¿ç”¨normalizeAPIKeysçš„ç›¸åŒé€»è¾‘ï¼šåˆ†å‰²api_keyå­—æ®µ
		keys := strings.Split(apiKey, ",")
		apiKeys := make([]string, 0, len(keys))
		for _, k := range keys {
			trimmed := strings.TrimSpace(k)
			if trimmed != "" {
				apiKeys = append(apiKeys, trimmed)
			}
		}

		// åºåˆ—åŒ–ä¸ºJSONæ•°ç»„
		apiKeysJSON, err := sonic.Marshal(apiKeys)
		if err != nil {
			continue // è·³è¿‡åºåˆ—åŒ–å¤±è´¥çš„
		}

		// æ›´æ–°æ•°æ®åº“
		_, err = s.db.ExecContext(ctx, `
			UPDATE channels
			SET api_keys = ?
			WHERE id = ?
		`, string(apiKeysJSON), id)
		if err == nil {
			migratedCount++
		}
	}

	if migratedCount > 0 {
		fmt.Printf("âœ… api_keyså­—æ®µè¿ç§»å®Œæˆï¼šä¿®å¤ %d æ¡æ¸ é“è®°å½•\n", migratedCount)
	}

	return nil
}

// ensureChannelNameUnique ç¡®ä¿channelsè¡¨çš„nameå­—æ®µå…·æœ‰UNIQUEçº¦æŸ
// ç®€åŒ–çš„å››æ­¥è¿ç§»æ–¹æ¡ˆï¼Œéµå¾ªKISSåŸåˆ™
func (s *SQLiteStore) ensureChannelNameUnique(ctx context.Context) error {
	// ç¬¬ä¸€æ­¥: åˆ é™¤æ—§çš„æ™®é€šç´¢å¼•
	if _, err := s.db.ExecContext(ctx, "DROP INDEX IF EXISTS idx_channels_name"); err != nil {
		return fmt.Errorf("drop old index: %w", err)
	}

	// ç¬¬äºŒæ­¥: æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨UNIQUEç´¢å¼•
	var count int
	err := s.db.QueryRowContext(ctx,
		"SELECT COUNT(*) FROM sqlite_master WHERE type = 'index' AND name = 'idx_channels_unique_name'",
	).Scan(&count)
	if err != nil {
		return fmt.Errorf("check unique index exists: %w", err)
	}
	if count > 0 {
		return nil // ç´¢å¼•å·²å­˜åœ¨ï¼Œé€€å‡º
	}

	// ç¬¬ä¸‰æ­¥: ä¿®å¤é‡å¤çš„nameæ•°æ®
	rows, err := s.db.QueryContext(ctx, `
		SELECT name, GROUP_CONCAT(id) AS ids
		FROM channels
		GROUP BY name
		HAVING COUNT(*) > 1
	`)
	if err != nil {
		return fmt.Errorf("find duplicates: %w", err)
	}
	defer rows.Close()

	duplicateCount := 0
	for rows.Next() {
		var name, idsStr string
		if err := rows.Scan(&name, &idsStr); err != nil {
			continue
		}

		ids := strings.Split(idsStr, ",")
		if len(ids) <= 1 {
			continue
		}

		duplicateCount++

		// ä¿ç•™ç¬¬ä¸€ä¸ªIDçš„nameä¸å˜ï¼Œå…¶ä»–IDçš„nameæ”¹ä¸º "åŸname+id"
		for i := 1; i < len(ids); i++ {
			newName := fmt.Sprintf("%s%s", name, ids[i])
			nowUnix := time.Now().Unix()
			_, err = s.db.ExecContext(ctx, `
				UPDATE channels SET name = ?, updated_at = ?
				WHERE id = ?
			`, newName, nowUnix, ids[i])
			if err != nil {
				return fmt.Errorf("fix duplicate name for id %s: %w", ids[i], err)
			}
		}
	}

	if duplicateCount > 0 {
		fmt.Printf("Fixed %d duplicate channel names\n", duplicateCount)
	}

	// ç¬¬å››æ­¥: åˆ›å»ºUNIQUEç´¢å¼•
	if _, err := s.db.ExecContext(ctx,
		"CREATE UNIQUE INDEX IF NOT EXISTS idx_channels_unique_name ON channels (NAME)",
	); err != nil {
		return fmt.Errorf("create unique index: %w", err)
	}

	return nil
}

// migrateCooldownToUnixTimestamp è¿ç§»å†·å´è¡¨çš„untilå­—æ®µä»TIMESTAMPåˆ°Unixæ—¶é—´æˆ³
// ç­–ç•¥ï¼šæ£€æµ‹å­—æ®µç±»å‹ï¼Œå¦‚æœæ˜¯TEXT/TIMESTAMPåˆ™é‡å»ºè¡¨ï¼Œå¦‚æœå·²ç»æ˜¯INTEGERåˆ™è·³è¿‡
func (s *SQLiteStore) migrateCooldownToUnixTimestamp(ctx context.Context) error {
	// æ£€æŸ¥cooldownsè¡¨çš„untilå­—æ®µç±»å‹
	needMigrateCooldowns := false
	rows, err := s.db.QueryContext(ctx, "PRAGMA table_info(cooldowns)")
	if err != nil {
		return fmt.Errorf("check cooldowns table: %w", err)
	}
	for rows.Next() {
		var cid int
		var name, typ string
		var notnull, pk int
		var dfltValue any
		if err := rows.Scan(&cid, &name, &typ, &notnull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == "until" && typ != "INTEGER" {
			needMigrateCooldowns = true
			break
		}
	}
	rows.Close()

	if needMigrateCooldowns {
		// é‡å»ºcooldownsè¡¨
		if err := s.rebuildCooldownsTable(ctx); err != nil {
			return fmt.Errorf("rebuild cooldowns table: %w", err)
		}
		fmt.Println("âœ… è¿ç§» cooldowns è¡¨ï¼šTIMESTAMP â†’ Unixæ—¶é—´æˆ³")
	}

	// æ£€æŸ¥key_cooldownsè¡¨çš„untilå­—æ®µç±»å‹
	needMigrateKeyCooldowns := false
	rows, err = s.db.QueryContext(ctx, "PRAGMA table_info(key_cooldowns)")
	if err != nil {
		return fmt.Errorf("check key_cooldowns table: %w", err)
	}
	for rows.Next() {
		var cid int
		var name, typ string
		var notnull, pk int
		var dfltValue any
		if err := rows.Scan(&cid, &name, &typ, &notnull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == "until" && typ != "INTEGER" {
			needMigrateKeyCooldowns = true
			break
		}
	}
	rows.Close()

	if needMigrateKeyCooldowns {
		// é‡å»ºkey_cooldownsè¡¨
		if err := s.rebuildKeyCooldownsTable(ctx); err != nil {
			return fmt.Errorf("rebuild key_cooldowns table: %w", err)
		}
		fmt.Println("âœ… è¿ç§» key_cooldowns è¡¨ï¼šTIMESTAMP â†’ Unixæ—¶é—´æˆ³")
	}

	return nil
}

// migrateLogsToUnixTimestamp è¿ç§»logsè¡¨çš„timeåˆ—åˆ°time_msï¼ˆUnixæ¯«ç§’æ—¶é—´æˆ³ï¼‰
// æ ¹æœ¬è§£å†³strftimeæ— æ³•è§£ææ—¶åŒºçš„é—®é¢˜
// rebuildLogsTableToUnixTimestamp é‡å»ºlogsè¡¨ï¼Œå°†timeå­—æ®µä»TIMESTAMPæ”¹ä¸ºBIGINTæ¯«ç§’
func (s *SQLiteStore) rebuildLogsTableToUnixTimestamp(ctx context.Context) error {
	// æ£€æŸ¥timeå­—æ®µç±»å‹æ˜¯å¦éœ€è¦é‡å»º
	var fieldType string
	err := s.db.QueryRowContext(ctx, `
		SELECT type FROM pragma_table_info('logs') WHERE name = 'time'
	`).Scan(&fieldType)
	if err != nil {
		return nil // è¡¨ä¸å­˜åœ¨æˆ–å­—æ®µä¸å­˜åœ¨ï¼Œè·³è¿‡
	}

	// å¦‚æœå·²ç»æ˜¯INTEGER/BIGINTï¼Œè·³è¿‡é‡å»º
	if fieldType == "INTEGER" || fieldType == "BIGINT" {
		return nil
	}

	fmt.Println("ğŸ”„ é‡å»º logs è¡¨ï¼štime(TIMESTAMP) â†’ time(BIGINT æ¯«ç§’)")

	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// 1. åˆ›å»ºæ–°è¡¨
	_, err = tx.ExecContext(ctx, `
		CREATE TABLE logs_new (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			time BIGINT NOT NULL,
			model TEXT,
			channel_id INTEGER,
			status_code INTEGER NOT NULL,
			message TEXT,
			duration REAL,
			is_streaming INTEGER NOT NULL DEFAULT 0,
			first_byte_time REAL,
			api_key_used TEXT,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE SET NULL
		)
	`)
	if err != nil {
		return fmt.Errorf("create new logs table: %w", err)
	}

	// 2. è¿ç§»æ•°æ®ï¼šè½¬æ¢TIMESTAMPä¸ºUnixæ¯«ç§’æ—¶é—´æˆ³
	_, err = tx.ExecContext(ctx, `
		INSERT INTO logs_new (id, time, model, channel_id, status_code, message, duration, is_streaming, first_byte_time, api_key_used)
		SELECT
			id,
			CAST(strftime('%s', substr(time, 1, 19)) AS INTEGER) * 1000 as time,
			model,
			channel_id,
			status_code,
			message,
			duration,
			is_streaming,
			first_byte_time,
			api_key_used
		FROM logs
	`)
	if err != nil {
		return fmt.Errorf("migrate logs data: %w", err)
	}

	// 3. åˆ é™¤æ—§è¡¨
	_, err = tx.ExecContext(ctx, `DROP TABLE logs`)
	if err != nil {
		return fmt.Errorf("drop old logs table: %w", err)
	}

	// 4. é‡å‘½åæ–°è¡¨
	_, err = tx.ExecContext(ctx, `ALTER TABLE logs_new RENAME TO logs`)
	if err != nil {
		return fmt.Errorf("rename logs table: %w", err)
	}

	// 5. é‡å»ºç´¢å¼•
	_, err = tx.ExecContext(ctx, `CREATE INDEX idx_logs_time ON logs(time)`)
	if err != nil {
		return fmt.Errorf("create time index: %w", err)
	}
	_, err = tx.ExecContext(ctx, `CREATE INDEX idx_logs_status ON logs(status_code)`)
	if err != nil {
		return fmt.Errorf("create status index: %w", err)
	}
	_, err = tx.ExecContext(ctx, `CREATE INDEX idx_logs_time_model ON logs(time, model)`)
	if err != nil {
		return fmt.Errorf("create time_model index: %w", err)
	}
	_, err = tx.ExecContext(ctx, `CREATE INDEX idx_logs_time_channel ON logs(time, channel_id)`)
	if err != nil {
		return fmt.Errorf("create time_channel index: %w", err)
	}
	_, err = tx.ExecContext(ctx, `CREATE INDEX idx_logs_time_status ON logs(time, status_code)`)
	if err != nil {
		return fmt.Errorf("create time_status index: %w", err)
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	fmt.Println("âœ… logs è¡¨é‡å»ºå®Œæˆ")
	return nil
}

// rebuildChannelsTableToUnixTimestamp é‡å»ºchannelsè¡¨ï¼Œå°†created_at/updated_atä»TIMESTAMPæ”¹ä¸ºBIGINTç§’
func (s *SQLiteStore) rebuildChannelsTableToUnixTimestamp(ctx context.Context) error {
	// æ£€æŸ¥created_atå­—æ®µç±»å‹æ˜¯å¦éœ€è¦é‡å»º
	var fieldType string
	err := s.db.QueryRowContext(ctx, `
		SELECT type FROM pragma_table_info('channels') WHERE name = 'created_at'
	`).Scan(&fieldType)
	if err != nil {
		return nil // è¡¨ä¸å­˜åœ¨æˆ–å­—æ®µä¸å­˜åœ¨ï¼Œè·³è¿‡
	}

	// å¦‚æœå·²ç»æ˜¯INTEGER/BIGINTï¼Œè·³è¿‡é‡å»º
	if fieldType == "INTEGER" || fieldType == "BIGINT" {
		return nil
	}

	fmt.Println("ğŸ”„ é‡å»º channels è¡¨ï¼šcreated_at/updated_at(TIMESTAMP) â†’ (BIGINT ç§’)")

	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// 1. åˆ›å»ºæ–°è¡¨
	_, err = tx.ExecContext(ctx, `
		CREATE TABLE channels_new (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			name TEXT NOT NULL,
			api_key TEXT NOT NULL,
			api_keys TEXT DEFAULT '[]',
			key_strategy TEXT DEFAULT 'sequential',
			url TEXT NOT NULL,
			priority INTEGER NOT NULL DEFAULT 0,
			models TEXT NOT NULL,
			model_redirects TEXT DEFAULT '{}',
			channel_type TEXT DEFAULT 'anthropic',
			enabled INTEGER NOT NULL DEFAULT 1,
			created_at BIGINT NOT NULL,
			updated_at BIGINT NOT NULL
		)
	`)
	if err != nil {
		return fmt.Errorf("create new channels table: %w", err)
	}

	// 2. è¿ç§»æ•°æ®ï¼šè½¬æ¢TIMESTAMPä¸ºUnixç§’æ—¶é—´æˆ³
	_, err = tx.ExecContext(ctx, `
		INSERT INTO channels_new (id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		SELECT
			id,
			name,
			api_key,
			COALESCE(api_keys, '[]'),
			COALESCE(key_strategy, 'sequential'),
			url,
			priority,
			models,
			COALESCE(model_redirects, '{}'),
			COALESCE(channel_type, 'anthropic'),
			enabled,
			CAST(strftime('%s', substr(created_at, 1, 19)) AS INTEGER) as created_at,
			CAST(strftime('%s', substr(updated_at, 1, 19)) AS INTEGER) as updated_at
		FROM channels
	`)
	if err != nil {
		return fmt.Errorf("migrate channels data: %w", err)
	}

	// 3. åˆ é™¤æ—§è¡¨
	_, err = tx.ExecContext(ctx, `DROP TABLE channels`)
	if err != nil {
		return fmt.Errorf("drop old channels table: %w", err)
	}

	// 4. é‡å‘½åæ–°è¡¨
	_, err = tx.ExecContext(ctx, `ALTER TABLE channels_new RENAME TO channels`)
	if err != nil {
		return fmt.Errorf("rename channels table: %w", err)
	}

	// 5. é‡å»ºå”¯ä¸€ç´¢å¼•
	_, err = tx.ExecContext(ctx, `CREATE UNIQUE INDEX idx_channels_unique_name ON channels(name)`)
	if err != nil {
		return fmt.Errorf("create unique name index: %w", err)
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	fmt.Println("âœ… channels è¡¨é‡å»ºå®Œæˆ")
	return nil
}

// rebuildTimestampTable é€šç”¨è¡¨é‡å»ºå‡½æ•°ï¼Œç”¨äºTIMESTAMPåˆ°Unixæ—¶é—´æˆ³è¿ç§»
// éµå¾ªDRYåŸåˆ™ï¼Œæ¶ˆé™¤é‡å¤çš„è¡¨é‡å»ºé€»è¾‘
func (s *SQLiteStore) rebuildTimestampTable(ctx context.Context, tableName, createTableSQL string) error {
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	tempTableName := tableName + "_new"

	// 1. åˆ›å»ºä¸´æ—¶è¡¨ï¼ˆæ–°ç»“æ„ï¼‰
	createSQL := strings.ReplaceAll(createTableSQL, tableName, tempTableName)
	if _, err := tx.ExecContext(ctx, createSQL); err != nil {
		return fmt.Errorf("create temp table: %w", err)
	}

	// 2. æ¸…ç†æ—§æ•°æ®ï¼ˆTIMESTAMPæ ¼å¼æ— æ³•å¯é è½¬æ¢ï¼‰
	fmt.Printf("  æ¸…ç†æ—§çš„%sè®°å½•ï¼ˆæ ¼å¼ä¸å…¼å®¹ï¼‰\n", tableName)

	// 3. åˆ é™¤æ—§è¡¨
	dropSQL := fmt.Sprintf("DROP TABLE %s", tableName)
	if _, err := tx.ExecContext(ctx, dropSQL); err != nil {
		return fmt.Errorf("drop old table: %w", err)
	}

	// 4. é‡å‘½åæ–°è¡¨
	renameSQL := fmt.Sprintf("ALTER TABLE %s RENAME TO %s", tempTableName, tableName)
	if _, err := tx.ExecContext(ctx, renameSQL); err != nil {
		return fmt.Errorf("rename table: %w", err)
	}

	return tx.Commit()
}

// rebuildCooldownsTable é‡å»ºcooldownsè¡¨ï¼Œè¿ç§»ç°æœ‰æ•°æ®
func (s *SQLiteStore) rebuildCooldownsTable(ctx context.Context) error {
	createSQL := `
		CREATE TABLE cooldowns (
			channel_id INTEGER PRIMARY KEY,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		)
	`
	return s.rebuildTimestampTable(ctx, "cooldowns", createSQL)
}

// rebuildKeyCooldownsTable é‡å»ºkey_cooldownsè¡¨ï¼Œè¿ç§»ç°æœ‰æ•°æ®
func (s *SQLiteStore) rebuildKeyCooldownsTable(ctx context.Context) error {
	createSQL := `
		CREATE TABLE key_cooldowns (
			channel_id INTEGER NOT NULL,
			key_index INTEGER NOT NULL,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			PRIMARY KEY(channel_id, key_index),
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		)
	`
	return s.rebuildTimestampTable(ctx, "key_cooldowns", createSQL)
}

func (s *SQLiteStore) Close() error {
	// ä¼˜é›…å…³é—­ï¼šé€šçŸ¥workeré€€å‡º
	if s.done != nil {
		close(s.done)
	}

	// ç­‰å¾…workerå¤„ç†å®Œæœ€åçš„åŒæ­¥ä»»åŠ¡ï¼ˆæœ€å¤šç­‰å¾…3ç§’ï¼‰
	time.Sleep(100 * time.Millisecond)

	return s.db.Close()
}

func (s *SQLiteStore) Vacuum(ctx context.Context) error {
	_, err := s.db.ExecContext(ctx, "VACUUM")
	return err
}

// CleanupLogsBefore æ¸…ç†æˆªæ­¢æ—¶é—´ä¹‹å‰çš„æ—¥å¿—ï¼ˆDIPï¼šé€šè¿‡æ¥å£æš´éœ²ç»´æŠ¤æ“ä½œï¼‰
func (s *SQLiteStore) CleanupLogsBefore(ctx context.Context, cutoff time.Time) error {
	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³
	cutoffMs := cutoff.UnixMilli()
	_, err := s.db.ExecContext(ctx, `DELETE FROM logs WHERE time < ?`, cutoffMs)
	return err
}

// prepareStmt è·å–æˆ–åˆ›å»ºé¢„ç¼–è¯‘è¯­å¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘SQLè§£æå¼€é”€ï¼‰
// ä½¿ç”¨åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼é¿å…é‡å¤ç¼–è¯‘ï¼šå…ˆæ— é”å¿«é€ŸæŸ¥æ‰¾ï¼Œæœªæ‰¾åˆ°æ—¶åŠ é”åˆ›å»º
func (s *SQLiteStore) prepareStmt(ctx context.Context, query string) (*sql.Stmt, error) {
	// å¿«é€Ÿè·¯å¾„ï¼šä»ç¼“å­˜è·å–ï¼ˆæ— é”ï¼‰
	if cached, ok := s.stmtCache.Load(query); ok {
		return cached.(*sql.Stmt), nil
	}

	// æ…¢é€Ÿè·¯å¾„ï¼šç¼–è¯‘æ–°è¯­å¥ï¼ˆéœ€è¦åŠ é”é¿å…é‡å¤ç¼–è¯‘ï¼‰
	s.stmtMux.Lock()
	defer s.stmtMux.Unlock()

	// åŒé‡æ£€æŸ¥ï¼šå†æ¬¡å°è¯•ä»ç¼“å­˜è·å–ï¼ˆé¿å…é”ç«äº‰æœŸé—´å…¶ä»–goroutineå·²åˆ›å»ºï¼‰
	if cached, ok := s.stmtCache.Load(query); ok {
		return cached.(*sql.Stmt), nil
	}

	// ç¼–è¯‘æ–°è¯­å¥
	stmt, err := s.db.PrepareContext(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("prepare statement: %w", err)
	}

	// ç¼“å­˜è¯­å¥
	s.stmtCache.Store(query, stmt)
	return stmt, nil
}

// prepareAllHotQueries é¢„ç¼–è¯‘æ‰€æœ‰çƒ­æŸ¥è¯¢ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šå¯åŠ¨æ—¶ä¸€æ¬¡æ€§ç¼–è¯‘ï¼‰
// ä½œç”¨ï¼šæ¶ˆé™¤é¦–æ¬¡æŸ¥è¯¢çš„ç¼–è¯‘å»¶è¿Ÿ20-30%ï¼Œæå‡å†·å¯åŠ¨æ€§èƒ½
func (s *SQLiteStore) prepareAllHotQueries(ctx context.Context) error {
	hotQueries := []string{
		// æ¸ é“æŸ¥è¯¢ï¼ˆæœ€çƒ­ï¼‰
		`SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		WHERE id = ?`,

		`SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		ORDER BY priority DESC, id ASC`,

		// å†·å´çŠ¶æ€æŸ¥è¯¢ï¼ˆçƒ­è·¯å¾„ï¼‰
		`SELECT until FROM cooldowns WHERE channel_id = ?`,
		`SELECT until FROM key_cooldowns WHERE channel_id = ? AND key_index = ?`,

		// æ—¥å¿—æ’å…¥ï¼ˆé«˜é¢‘ï¼‰
		`INSERT INTO logs(time, model, channel_id, status_code, message, duration, is_streaming, first_byte_time, api_key_used)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)`,

		// ç»Ÿè®¡æŸ¥è¯¢ï¼ˆå®šæœŸè°ƒç”¨ï¼‰
		`SELECT channel_id, COALESCE(c.name, 'ç³»ç»Ÿ') AS channel_name, COALESCE(l.model, '') AS model,
			SUM(CASE WHEN l.status_code >= 200 AND l.status_code < 300 THEN 1 ELSE 0 END) AS success,
			SUM(CASE WHEN l.status_code < 200 OR l.status_code >= 300 THEN 1 ELSE 0 END) AS error,
			COUNT(*) AS total
		FROM logs l 
		LEFT JOIN channels c ON c.id = l.channel_id
		WHERE l.time >= ?
		GROUP BY l.channel_id, c.name, l.model ORDER BY channel_name ASC, model ASC`,
	}

	preparedCount := 0
	for _, query := range hotQueries {
		if _, err := s.prepareStmt(ctx, query); err != nil {
			return fmt.Errorf("prepare query failed: %w", err)
		}
		preparedCount++
	}

	fmt.Printf("âœ… çƒ­æŸ¥è¯¢é¢„ç¼–è¯‘å®Œæˆï¼š%d æ¡è¯­å¥\n", preparedCount)
	return nil
}

// ---- Store interface impl ----

func (s *SQLiteStore) ListConfigs(ctx context.Context) ([]*Config, error) {
	// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥å‡å°‘SQLè§£æå¼€é”€
	query := `
		SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		ORDER BY priority DESC, id ASC
	`
	stmt, err := s.prepareStmt(ctx, query)
	if err != nil {
		return nil, err
	}

	rows, err := stmt.QueryContext(ctx)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰«æå™¨
	scanner := NewConfigScanner()
	return scanner.ScanConfigs(rows)
}

func (s *SQLiteStore) GetConfig(ctx context.Context, id int64) (*Config, error) {
	// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥
	query := `
		SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		WHERE id = ?
	`
	stmt, err := s.prepareStmt(ctx, query)
	if err != nil {
		return nil, err
	}

	row := stmt.QueryRowContext(ctx, id)

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰«æå™¨
	scanner := NewConfigScanner()
	config, err := scanner.ScanConfig(row)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, errors.New("not found")
		}
		return nil, err
	}
	return config, nil
}

func (s *SQLiteStore) CreateConfig(ctx context.Context, c *Config) (*Config, error) {
	nowUnix := time.Now().Unix() // Unixç§’æ—¶é—´æˆ³
	modelsStr, _ := serializeModels(c.Models)
	modelRedirectsStr, _ := serializeModelRedirects(c.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(c)
	apiKeysStr, _ := sonic.Marshal(c.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„

	// ä½¿ç”¨GetChannelTypeç¡®ä¿é»˜è®¤å€¼
	channelType := c.GetChannelType()
	keyStrategy := c.GetKeyStrategy() // ç¡®ä¿é»˜è®¤å€¼

	res, err := s.db.ExecContext(ctx, `
		INSERT INTO channels(name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`, c.Name, c.APIKey, string(apiKeysStr), keyStrategy, c.URL, c.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(c.Enabled), nowUnix, nowUnix)

	if err != nil {
		return nil, err
	}
	id, _ := res.LastInsertId()

	// è·å–å®Œæ•´çš„é…ç½®ä¿¡æ¯
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return config, nil
}

func (s *SQLiteStore) UpdateConfig(ctx context.Context, id int64, upd *Config) (*Config, error) {
	if upd == nil {
		return nil, errors.New("update payload cannot be nil")
	}

	// ç¡®è®¤ç›®æ ‡å­˜åœ¨ï¼Œä¿æŒä¸ä¹‹å‰é€»è¾‘ä¸€è‡´
	if _, err := s.GetConfig(ctx, id); err != nil {
		return nil, err
	}

	name := strings.TrimSpace(upd.Name)
	apiKey := strings.TrimSpace(upd.APIKey)
	url := strings.TrimSpace(upd.URL)
	modelsStr, _ := serializeModels(upd.Models)
	modelRedirectsStr, _ := serializeModelRedirects(upd.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(upd)
	apiKeysStr, _ := sonic.Marshal(upd.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„
	channelType := upd.GetChannelType()         // ç¡®ä¿é»˜è®¤å€¼
	keyStrategy := upd.GetKeyStrategy()         // ç¡®ä¿é»˜è®¤å€¼
	updatedAtUnix := time.Now().Unix()          // Unixç§’æ—¶é—´æˆ³

	_, err := s.db.ExecContext(ctx, `
		UPDATE channels
		SET name=?, api_key=?, api_keys=?, key_strategy=?, url=?, priority=?, models=?, model_redirects=?, channel_type=?, enabled=?, updated_at=?
		WHERE id=?
	`, name, apiKey, string(apiKeysStr), keyStrategy, url, upd.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(upd.Enabled), updatedAtUnix, id)
	if err != nil {
		return nil, err
	}

	// è·å–æ›´æ–°åçš„é…ç½®
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return config, nil
}

func (s *SQLiteStore) ReplaceConfig(ctx context.Context, c *Config) (*Config, error) {
	nowUnix := time.Now().Unix() // Unixç§’æ—¶é—´æˆ³
	modelsStr, _ := serializeModels(c.Models)
	modelRedirectsStr, _ := serializeModelRedirects(c.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(c)
	apiKeysStr, _ := sonic.Marshal(c.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„
	channelType := c.GetChannelType()         // ç¡®ä¿é»˜è®¤å€¼
	keyStrategy := c.GetKeyStrategy()         // ç¡®ä¿é»˜è®¤å€¼
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO channels(name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		ON CONFLICT(NAME) DO UPDATE SET
			api_key = excluded.api_key,
			api_keys = excluded.api_keys,
			key_strategy = excluded.key_strategy,
			url = excluded.url,
			priority = excluded.priority,
			models = excluded.models,
			model_redirects = excluded.model_redirects,
			channel_type = excluded.channel_type,
			enabled = excluded.enabled,
			updated_at = excluded.updated_at
	`, c.Name, c.APIKey, string(apiKeysStr), keyStrategy, c.URL, c.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(c.Enabled), nowUnix, nowUnix)
	if err != nil {
		return nil, err
	}

	// è·å–å®é™…çš„è®°å½•IDï¼ˆå¯èƒ½æ˜¯æ–°åˆ›å»ºçš„æˆ–å·²å­˜åœ¨çš„ï¼‰
	var id int64
	err = s.db.QueryRowContext(ctx, `SELECT id FROM channels WHERE name = ?`, c.Name).Scan(&id)
	if err != nil {
		return nil, err
	}

	// è·å–å®Œæ•´çš„é…ç½®ä¿¡æ¯
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// æ³¨æ„: ReplaceConfigé€šå¸¸åœ¨æ‰¹é‡å¯¼å…¥æ—¶ä½¿ç”¨ï¼Œæœ€åä¼šç»Ÿä¸€è°ƒç”¨SyncAllChannelsToRedis
	// è¿™é‡Œä¸åšå•ç‹¬åŒæ­¥ï¼Œé¿å…CSVå¯¼å…¥æ—¶çš„Næ¬¡Redisæ“ä½œ

	return config, nil
}

func (s *SQLiteStore) DeleteConfig(ctx context.Context, id int64) error {
	// æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨ï¼ˆå¹‚ç­‰æ€§ï¼‰
	if _, err := s.GetConfig(ctx, id); err != nil {
		if strings.Contains(err.Error(), "not found") {
			return nil // è®°å½•ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
		}
		return err
	}

	// ä»SQLiteåˆ é™¤
	_, err := s.db.ExecContext(ctx, `DELETE FROM channels WHERE id = ?`, id)
	if err != nil {
		return err
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return nil
}

func (s *SQLiteStore) GetCooldownUntil(ctx context.Context, configID int64) (time.Time, bool) {
	row := s.db.QueryRowContext(ctx, `SELECT until FROM cooldowns WHERE channel_id = ?`, configID)
	return scanUnixTimestamp(row)
}

func (s *SQLiteStore) SetCooldown(ctx context.Context, configID int64, until time.Time) error {
	now := time.Now()
	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—å†·å´æŒç»­æ—¶é—´å’Œæ—¶é—´æˆ³
	durMs := calculateCooldownDuration(until, now)
	unixTime := toUnixTimestamp(until)

	_, err := s.db.ExecContext(ctx, `
		INSERT INTO cooldowns(channel_id, until, duration_ms) VALUES(?, ?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, unixTime, durMs)
	return err
}

// BumpCooldownOnError æŒ‡æ•°é€€é¿ï¼šé”™è¯¯ç¿»å€ï¼ˆæœ€å°1sï¼Œæœ€å¤§30mï¼‰ï¼ŒæˆåŠŸæ¸…é›¶
func (s *SQLiteStore) BumpCooldownOnError(ctx context.Context, configID int64, now time.Time) (time.Duration, error) {
	var unixTime int64
	var durMs int64
	err := s.db.QueryRowContext(ctx, `
		SELECT until, COALESCE(duration_ms, 0)
		FROM cooldowns
		WHERE channel_id = ?
	`, configID).Scan(&unixTime, &durMs)

	if err != nil && !errors.Is(err, sql.ErrNoRows) {
		return 0, err
	}

	// ä»Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºtime.Time
	until := time.Unix(unixTime, 0)

	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´
	next := calculateBackoffDuration(durMs, until, now)

	newUntil := now.Add(next)
	// è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³å­˜å‚¨
	_, err = s.db.ExecContext(ctx, `
		INSERT INTO cooldowns(channel_id, until, duration_ms) VALUES(?, ?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, newUntil.Unix(), int64(next/time.Millisecond))

	if err != nil {
		return 0, err
	}
	return next, nil
}

func (s *SQLiteStore) ResetCooldown(ctx context.Context, configID int64) error {
	// åˆ é™¤è®°å½•ï¼Œç­‰æ•ˆäºå†·å´ä¸º0
	_, err := s.db.ExecContext(ctx, `DELETE FROM cooldowns WHERE channel_id = ?`, configID)
	return err
}

func (s *SQLiteStore) AddLog(ctx context.Context, e *LogEntry) error {
	if e.Time.Time.IsZero() {
		e.Time = JSONTime{time.Now()}
	}

	// æ¸…ç†å•è°ƒæ—¶é’Ÿä¿¡æ¯ï¼Œç¡®ä¿æ—¶é—´æ ¼å¼æ ‡å‡†åŒ–
	cleanTime := e.Time.Time.Round(0) // ç§»é™¤å•è°ƒæ—¶é’Ÿéƒ¨åˆ†

	// Unixæ—¶é—´æˆ³ï¼šç›´æ¥å­˜å‚¨æ¯«ç§’çº§Unixæ—¶é—´æˆ³
	timeMs := cleanTime.UnixMilli()

	// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥
	query := `
		INSERT INTO logs(time, model, channel_id, status_code, message, duration, is_streaming, first_byte_time, api_key_used)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)
	`
	stmt, err := s.prepareStmt(ctx, query)
	if err != nil {
		return err
	}

	_, err = stmt.ExecContext(ctx, timeMs, e.Model, e.ChannelID, e.StatusCode, e.Message, e.Duration, e.IsStreaming, e.FirstByteTime, e.APIKeyUsed)
	return err
}

func (s *SQLiteStore) ListLogs(ctx context.Context, since time.Time, limit, offset int, filter *LogFilter) ([]*LogEntry, error) {
	// ä½¿ç”¨æŸ¥è¯¢æ„å»ºå™¨æ„å»ºå¤æ‚æŸ¥è¯¢
	baseQuery := `
		SELECT l.id, l.time, l.model, l.channel_id, c.name AS channel_name,
		       l.status_code, l.message, l.duration, l.is_streaming, l.first_byte_time, l.api_key_used
		FROM logs l
		LEFT JOIN channels c ON c.id = l.channel_id`

	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³ï¼Œéœ€è¦è½¬æ¢ä¸ºUnixæ¯«ç§’è¿›è¡Œæ¯”è¾ƒ
	sinceMs := since.UnixMilli()

	qb := NewQueryBuilder(baseQuery).
		Where("l.time >= ?", sinceMs).
		ApplyFilter(filter)

	suffix := "ORDER BY l.time DESC LIMIT ? OFFSET ?"
	query, args := qb.BuildWithSuffix(suffix)
	args = append(args, limit, offset)

	rows, err := s.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	out := []*LogEntry{}
	for rows.Next() {
		var e LogEntry
		var cfgID sql.NullInt64
		var chName sql.NullString
		var duration sql.NullFloat64
		var isStreamingInt int
		var firstByteTime sql.NullFloat64
		var timeMs int64 // Unixæ¯«ç§’æ—¶é—´æˆ³
		var apiKeyUsed sql.NullString

		if err := rows.Scan(&e.ID, &timeMs, &e.Model, &cfgID, &chName,
			&e.StatusCode, &e.Message, &duration, &isStreamingInt, &firstByteTime, &apiKeyUsed); err != nil {
			return nil, err
		}

		// è½¬æ¢Unixæ¯«ç§’æ—¶é—´æˆ³ä¸ºtime.Time
		e.Time = JSONTime{time.UnixMilli(timeMs)}

		if cfgID.Valid {
			id := cfgID.Int64
			e.ChannelID = &id
		}
		if chName.Valid {
			e.ChannelName = chName.String
		}
		if duration.Valid {
			e.Duration = duration.Float64
		}
		e.IsStreaming = isStreamingInt != 0
		if firstByteTime.Valid {
			fbt := firstByteTime.Float64
			e.FirstByteTime = &fbt
		}
		if apiKeyUsed.Valid && apiKeyUsed.String != "" {
			e.APIKeyUsed = maskAPIKey(apiKeyUsed.String)
		}
		out = append(out, &e)
	}
	return out, nil
}

func (s *SQLiteStore) Aggregate(ctx context.Context, since time.Time, bucket time.Duration) ([]MetricPoint, error) {
	// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨SQL GROUP BYè¿›è¡Œæ•°æ®åº“å±‚èšåˆï¼Œé¿å…å†…å­˜èšåˆ
	// åŸæ–¹æ¡ˆï¼šåŠ è½½æ‰€æœ‰æ—¥å¿—åˆ°å†…å­˜èšåˆï¼ˆ10ä¸‡æ¡æ—¥å¿—éœ€2-5ç§’ï¼Œå ç”¨100-200MBå†…å­˜ï¼‰
	// æ–°æ–¹æ¡ˆï¼šæ•°æ®åº“èšåˆï¼ˆæŸ¥è¯¢æ—¶é—´-80%ï¼Œå†…å­˜å ç”¨-90%ï¼‰

	bucketSeconds := int64(bucket.Seconds())
	sinceUnix := since.Unix()

	// SQLèšåˆæŸ¥è¯¢ï¼šä½¿ç”¨Unixæ—¶é—´æˆ³é™¤æ³•å®ç°æ—¶é—´æ¡¶åˆ†ç»„
	// æ€§èƒ½ä¼˜åŒ–ï¼štimeå­—æ®µä¸ºBIGINTæ¯«ç§’æ—¶é—´æˆ³ï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡10-100å€
	// bucket_ts = (unix_timestamp_seconds / bucket_seconds) * bucket_seconds
	query := `
		SELECT
			((l.time / 1000) / ?) * ? AS bucket_ts,
			COALESCE(c.name, 'æœªçŸ¥æ¸ é“') AS channel_name,
			SUM(CASE WHEN l.status_code >= 200 AND l.status_code < 300 THEN 1 ELSE 0 END) AS success,
			SUM(CASE WHEN l.status_code < 200 OR l.status_code >= 300 THEN 1 ELSE 0 END) AS error
		FROM logs l
		LEFT JOIN channels c ON l.channel_id = c.id
		WHERE (l.time / 1000) >= ?
		GROUP BY bucket_ts, channel_name
		ORDER BY bucket_ts ASC
	`
	stmt, err := s.prepareStmt(ctx, query)
	if err != nil {
		return nil, err
	}

	rows, err := stmt.QueryContext(ctx, bucketSeconds, bucketSeconds, sinceUnix)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	// è§£æèšåˆç»“æœï¼ŒæŒ‰æ—¶é—´æ¡¶é‡ç»„
	mapp := make(map[int64]*MetricPoint)
	for rows.Next() {
		var bucketTs int64
		var channelName string
		var success, errorCount int

		if err := rows.Scan(&bucketTs, &channelName, &success, &errorCount); err != nil {
			return nil, err
		}

		// è·å–æˆ–åˆ›å»ºæ—¶é—´æ¡¶
		mp, ok := mapp[bucketTs]
		if !ok {
			mp = &MetricPoint{
				Ts:       time.Unix(bucketTs, 0),
				Channels: make(map[string]ChannelMetric),
			}
			mapp[bucketTs] = mp
		}

		// æ›´æ–°æ€»ä½“ç»Ÿè®¡
		mp.Success += success
		mp.Error += errorCount

		// æ›´æ–°æ¸ é“ç»Ÿè®¡
		mp.Channels[channelName] = ChannelMetric{
			Success: success,
			Error:   errorCount,
		}
	}

	// ç”Ÿæˆå®Œæ•´çš„æ—¶é—´åºåˆ—ï¼ˆå¡«å……ç©ºæ¡¶ï¼‰
	out := []MetricPoint{}
	now := time.Now()
	endTime := now.Truncate(bucket).Add(bucket)
	startTime := since.Truncate(bucket)

	for t := startTime; t.Before(endTime); t = t.Add(bucket) {
		ts := t.Unix()
		if mp, ok := mapp[ts]; ok {
			out = append(out, *mp)
		} else {
			out = append(out, MetricPoint{
				Ts:       t,
				Channels: make(map[string]ChannelMetric),
			})
		}
	}

	// å·²æŒ‰æ—¶é—´å‡åºï¼ˆGROUP BY bucket_ts ASCï¼‰
	return out, nil
}

func (s *SQLiteStore) NextRR(ctx context.Context, model string, priority int, n int) int {
	if n <= 0 {
		return 0
	}

	key := fmt.Sprintf("%s|%d", model, priority)
	tx, err := s.db.BeginTx(ctx, &sql.TxOptions{})
	if err != nil {
		return 0
	}
	defer func() { _ = tx.Rollback() }()

	var cur int
	err = tx.QueryRowContext(ctx, `SELECT idx FROM rr WHERE KEY = ?`, key).Scan(&cur)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			cur = 0
			if _, err := tx.ExecContext(ctx, `INSERT INTO rr(key, idx) VALUES(?, ?)`, key, 0); err != nil {
				return 0
			}
		} else {
			return 0
		}
	}

	if cur >= n {
		cur = 0
	}

	next := cur + 1
	if next >= n {
		next = 0
	}

	if _, err := tx.ExecContext(ctx, `UPDATE rr SET idx = ? WHERE KEY = ?`, next, key); err != nil {
		return cur
	}

	_ = tx.Commit()
	return cur
}

func (s *SQLiteStore) SetRR(ctx context.Context, model string, priority int, idx int) error {
	key := fmt.Sprintf("%s|%d", model, priority)
	_, err := s.db.ExecContext(ctx, `INSERT OR REPLACE INTO rr (key, idx) VALUES (?, ?)`, key, idx)
	return err
}

// GetStats å®ç°ç»Ÿè®¡åŠŸèƒ½ï¼ŒæŒ‰æ¸ é“å’Œæ¨¡å‹ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ¬¡æ•°
func (s *SQLiteStore) GetStats(ctx context.Context, since time.Time, filter *LogFilter) ([]StatsEntry, error) {
	// ä½¿ç”¨æŸ¥è¯¢æ„å»ºå™¨æ„å»ºç»Ÿè®¡æŸ¥è¯¢
	baseQuery := `
		SELECT
			l.channel_id,
			COALESCE(c.name, 'ç³»ç»Ÿ') AS channel_name,
			COALESCE(l.model, '') AS model,
			SUM(CASE WHEN l.status_code >= 200 AND l.status_code < 300 THEN 1 ELSE 0 END) AS success,
			SUM(CASE WHEN l.status_code < 200 OR l.status_code >= 300 THEN 1 ELSE 0 END) AS error,
			COUNT(*) AS total
		FROM logs l
		LEFT JOIN channels c ON c.id = l.channel_id`

	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³
	sinceMs := since.UnixMilli()

	qb := NewQueryBuilder(baseQuery).
		Where("l.time >= ?", sinceMs).
		ApplyFilter(filter)

	suffix := "GROUP BY l.channel_id, c.name, l.model ORDER BY channel_name ASC, model ASC"
	query, args := qb.BuildWithSuffix(suffix)

	rows, err := s.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var stats []StatsEntry
	for rows.Next() {
		var entry StatsEntry
		err := rows.Scan(&entry.ChannelID, &entry.ChannelName, &entry.Model,
			&entry.Success, &entry.Error, &entry.Total)
		if err != nil {
			return nil, err
		}
		stats = append(stats, entry)
	}

	return stats, nil
}

// LoadChannelsFromRedis ä»Redisæ¢å¤æ¸ é“æ•°æ®åˆ°SQLite (å¯åŠ¨æ—¶æ•°æ®åº“æ¢å¤æœºåˆ¶)
func (s *SQLiteStore) LoadChannelsFromRedis(ctx context.Context) error {
	if !s.redisSync.IsEnabled() {
		return nil
	}

	// ä»RedisåŠ è½½æ‰€æœ‰æ¸ é“é…ç½®
	configs, err := s.redisSync.LoadChannelsFromRedis(ctx)
	if err != nil {
		return fmt.Errorf("load from redis: %w", err)
	}

	if len(configs) == 0 {
		fmt.Println("No channels found in Redis")
		return nil
	}

	fmt.Printf("Restoring %d channels from Redis...\n", len(configs))

	// ä½¿ç”¨äº‹åŠ¡ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ (ACIDåŸåˆ™)
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return fmt.Errorf("begin transaction: %w", err)
	}
	defer func() { _ = tx.Rollback() }()

	nowUnix := time.Now().Unix()
	successCount := 0

	for _, config := range configs {
		// æ ‡å‡†åŒ–æ•°æ®ï¼šç¡®ä¿é»˜è®¤å€¼æ­£ç¡®å¡«å……
		modelsStr, _ := serializeModels(config.Models)
		modelRedirectsStr, _ := serializeModelRedirects(config.ModelRedirects)
		apiKeysStr, _ := sonic.Marshal(config.APIKeys)
		channelType := config.GetChannelType() // å¼ºåˆ¶ä½¿ç”¨é»˜è®¤å€¼anthropic
		keyStrategy := config.GetKeyStrategy() // å¼ºåˆ¶ä½¿ç”¨é»˜è®¤å€¼sequential

		// ä½¿ç”¨å®Œæ•´å­—æ®µåˆ—è¡¨ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼ˆåŒ…å«æ‰€æœ‰æ–°å­—æ®µï¼‰
		_, err := tx.ExecContext(ctx, `
			INSERT OR REPLACE INTO channels(
				name, api_key, api_keys, key_strategy, url, priority,
				models, model_redirects, channel_type, enabled, created_at, updated_at
			)
			VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		`, config.Name, config.APIKey, string(apiKeysStr), keyStrategy, config.URL, config.Priority,
			modelsStr, modelRedirectsStr, channelType, boolToInt(config.Enabled), nowUnix, nowUnix)

		if err != nil {
			fmt.Printf("Warning: failed to restore channel %s: %v\n", config.Name, err)
			continue
		}
		successCount++
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	fmt.Printf("Successfully restored %d/%d channels from Redis\n", successCount, len(configs))
	return nil
}

// SyncAllChannelsToRedis å°†æ‰€æœ‰æ¸ é“åŒæ­¥åˆ°Redis (æ‰¹é‡åŒæ­¥ï¼Œåˆå§‹åŒ–æ—¶ä½¿ç”¨)
func (s *SQLiteStore) SyncAllChannelsToRedis(ctx context.Context) error {
	if !s.redisSync.IsEnabled() {
		return nil
	}

	configs, err := s.ListConfigs(ctx)
	if err != nil {
		return fmt.Errorf("list configs: %w", err)
	}

	if len(configs) == 0 {
		fmt.Println("No channels to sync to Redis")
		return nil
	}

	// è§„èŒƒåŒ–æ‰€æœ‰Configå¯¹è±¡çš„é»˜è®¤å€¼ï¼ˆç¡®ä¿Redisä¸­æ•°æ®å®Œæ•´æ€§ï¼‰
	normalizeConfigDefaults(configs)

	fmt.Printf("Syncing %d channels to Redis...\n", len(configs))

	if err := s.redisSync.SyncAllChannels(ctx, configs); err != nil {
		return fmt.Errorf("sync to redis: %w", err)
	}

	fmt.Printf("Successfully synced %d channels to Redis\n", len(configs))
	return nil
}

// redisSyncWorker å¼‚æ­¥RedisåŒæ­¥workerï¼ˆåå°goroutineï¼‰
func (s *SQLiteStore) redisSyncWorker() {
	ctx := context.Background()

	for {
		select {
		case <-s.syncCh:
			// æ‰§è¡ŒåŒæ­¥æ“ä½œ
			if err := s.doSyncAllChannels(ctx); err != nil {
				fmt.Printf("Warning: Async Redis sync failed: %v\n", err)
			}
		case <-s.done:
			// ä¼˜é›…å…³é—­ï¼šå¤„ç†å®Œæœ€åä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
			select {
			case <-s.syncCh:
				_ = s.doSyncAllChannels(ctx)
			default:
			}
			return
		}
	}
}

// triggerAsyncSync è§¦å‘å¼‚æ­¥RedisåŒæ­¥ï¼ˆéé˜»å¡ï¼‰
func (s *SQLiteStore) triggerAsyncSync() {
	if s.redisSync == nil || !s.redisSync.IsEnabled() {
		return
	}

	// éé˜»å¡å‘é€ï¼ˆå¦‚æœchannelå·²æ»¡åˆ™è·³è¿‡ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹ï¼‰
	select {
	case s.syncCh <- struct{}{}:
		// æˆåŠŸå‘é€ä¿¡å·
	default:
		// channelå·²æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œè·³è¿‡ï¼ˆå»é‡ï¼‰
	}
}

// doSyncAllChannels å®é™…æ‰§è¡ŒåŒæ­¥æ“ä½œï¼ˆworkerå†…éƒ¨è°ƒç”¨ï¼‰
func (s *SQLiteStore) doSyncAllChannels(ctx context.Context) error {
	configs, err := s.ListConfigs(ctx)
	if err != nil {
		return fmt.Errorf("list configs: %w", err)
	}

	// è§„èŒƒåŒ–é»˜è®¤å€¼åå†åŒæ­¥ï¼ˆä¸SyncAllChannelsToRedisä¿æŒä¸€è‡´ï¼‰
	normalizeConfigDefaults(configs)

	return s.redisSync.SyncAllChannels(ctx, configs)
}

// normalizeConfigDefaults è§„èŒƒåŒ–Configå¯¹è±¡çš„é»˜è®¤å€¼å­—æ®µï¼ˆDRYåŸåˆ™ï¼šç»Ÿä¸€è§„èŒƒåŒ–é€»è¾‘ï¼‰
// ç¡®ä¿åºåˆ—åŒ–åˆ°Redisæ—¶æ‰€æœ‰å­—æ®µéƒ½æœ‰æ­£ç¡®çš„é»˜è®¤å€¼ï¼Œé¿å…ç©ºå€¼æ±¡æŸ“
func normalizeConfigDefaults(configs []*Config) {
	for _, config := range configs {
		// å¼ºåˆ¶å¡«å……channel_typeé»˜è®¤å€¼ï¼ˆé¿å…ç©ºå­—ç¬¦ä¸²åºåˆ—åŒ–åˆ°Redisï¼‰
		if config.ChannelType == "" {
			config.ChannelType = "anthropic"
		}
		// å¼ºåˆ¶å¡«å……key_strategyé»˜è®¤å€¼
		if config.KeyStrategy == "" {
			config.KeyStrategy = "sequential"
		}
		// ç¡®ä¿model_redirectsä¸ä¸ºnilï¼ˆé¿å…åºåˆ—åŒ–ä¸ºnullï¼‰
		if config.ModelRedirects == nil {
			config.ModelRedirects = make(map[string]string)
		}
		// ç¡®ä¿api_keysä¸ä¸ºnil
		if config.APIKeys == nil {
			config.APIKeys = []string{}
		}
	}
}

// CheckDatabaseExists æ£€æŸ¥SQLiteæ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
func CheckDatabaseExists(dbPath string) bool {
	if _, err := os.Stat(dbPath); err != nil {
		return false
	}
	return true
}

// è¾…åŠ©å‡½æ•°
func boolToInt(b bool) int {
	if b {
		return 1
	}
	return 0
}

// ==================== Keyçº§åˆ«å†·å´æœºåˆ¶ ====================

// GetKeyCooldownUntil æŸ¥è¯¢æŒ‡å®šKeyçš„å†·å´æˆªæ­¢æ—¶é—´
func (s *SQLiteStore) GetKeyCooldownUntil(ctx context.Context, configID int64, keyIndex int) (time.Time, bool) {
	row := s.db.QueryRowContext(ctx, `
		SELECT until FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex)
	return scanUnixTimestamp(row)
}

// BumpKeyCooldownOnError Keyçº§åˆ«æŒ‡æ•°é€€é¿ï¼šé”™è¯¯ç¿»å€ï¼ˆæœ€å°1sï¼Œæœ€å¤§30mï¼‰
func (s *SQLiteStore) BumpKeyCooldownOnError(ctx context.Context, configID int64, keyIndex int, now time.Time) (time.Duration, error) {
	var unixTime int64
	var durMs int64
	err := s.db.QueryRowContext(ctx, `
		SELECT until, COALESCE(duration_ms, 0)
		FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex).Scan(&unixTime, &durMs)

	if err != nil && !errors.Is(err, sql.ErrNoRows) {
		return 0, err
	}

	// ä»Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºtime.Time
	until := time.Unix(unixTime, 0)

	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´
	next := calculateBackoffDuration(durMs, until, now)

	newUntil := now.Add(next)
	// è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³å­˜å‚¨
	_, err = s.db.ExecContext(ctx, `
		INSERT INTO key_cooldowns(channel_id, key_index, until, duration_ms) VALUES(?, ?, ?, ?)
		ON CONFLICT(channel_id, key_index) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, keyIndex, newUntil.Unix(), int64(next/time.Millisecond))

	if err != nil {
		return 0, err
	}
	return next, nil
}

// SetKeyCooldown è®¾ç½®æŒ‡å®šKeyçš„å†·å´æˆªæ­¢æ—¶é—´
func (s *SQLiteStore) SetKeyCooldown(ctx context.Context, configID int64, keyIndex int, until time.Time) error {
	now := time.Now()
	durationMs := calculateCooldownDuration(until, now)
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO key_cooldowns(channel_id, key_index, until, duration_ms) VALUES(?, ?, ?, ?)
		ON CONFLICT(channel_id, key_index) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, keyIndex, until.Unix(), durationMs)
	return err
}

// ResetKeyCooldown é‡ç½®æŒ‡å®šKeyçš„å†·å´çŠ¶æ€
func (s *SQLiteStore) ResetKeyCooldown(ctx context.Context, configID int64, keyIndex int) error {
	_, err := s.db.ExecContext(ctx, `
		DELETE FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex)
	return err
}

// ==================== Keyçº§åˆ«è½®è¯¢æœºåˆ¶ ====================

// NextKeyRR è·å–ä¸‹ä¸€ä¸ªè½®è¯¢Keyç´¢å¼•ï¼ˆå¸¦è‡ªåŠ¨å¢é‡ï¼‰
func (s *SQLiteStore) NextKeyRR(ctx context.Context, configID int64, keyCount int) int {
	if keyCount <= 0 {
		return 0
	}

	var idx int
	err := s.db.QueryRowContext(ctx, `
		SELECT idx FROM key_rr WHERE channel_id = ?
	`, configID).Scan(&idx)

	if err != nil {
		// æ²¡æœ‰è®°å½•ï¼Œä»0å¼€å§‹
		return 0
	}

	// ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
	return idx % keyCount
}

// SetKeyRR è®¾ç½®æ¸ é“çš„Keyè½®è¯¢æŒ‡é’ˆ
func (s *SQLiteStore) SetKeyRR(ctx context.Context, configID int64, idx int) error {
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO key_rr(channel_id, idx) VALUES(?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET idx = excluded.idx
	`, configID, idx)
	return err
}
