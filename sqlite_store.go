package main

import (
	"context"
	"database/sql"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/bytedance/sonic"
	_ "modernc.org/sqlite"
)

type SQLiteStore struct {
	db        *sql.DB    // ä¸»æ•°æ®åº“ï¼ˆchannels, cooldowns, rrï¼‰
	logDB     *sql.DB    // æ—¥å¿—æ•°æ®åº“ï¼ˆlogsï¼‰- æ‹†åˆ†ä»¥å‡å°‘é”ç«äº‰å’Œç®€åŒ–å¤‡ä»½
	redisSync *RedisSync // RedisåŒæ­¥å®¢æˆ·ç«¯ (OCP: å¼€æ”¾æ‰©å±•ï¼Œå°é—­ä¿®æ”¹)

	// âš ï¸ å†…å­˜æ•°æ®åº“å®ˆæŠ¤è¿æ¥ï¼ˆ2025-10-05 P0ä¿®å¤ï¼‰
	// å†…å­˜æ¨¡å¼ä¸‹ï¼ŒæŒæœ‰ä¸€ä¸ªæ°¸ä¸å…³é—­çš„è¿æ¥ï¼Œç¡®ä¿æ•°æ®åº“ä¸è¢«é”€æ¯
	keeperConn *sql.Conn // å®ˆæŠ¤è¿æ¥ï¼ˆä»…å†…å­˜æ¨¡å¼ä½¿ç”¨ï¼‰

	// å¼‚æ­¥RedisåŒæ­¥æœºåˆ¶ï¼ˆæ€§èƒ½ä¼˜åŒ–: é¿å…åŒæ­¥ç­‰å¾…ï¼‰
	syncCh chan struct{} // åŒæ­¥è§¦å‘ä¿¡å·ï¼ˆæ— ç¼“å†²ï¼Œå»é‡åˆå¹¶å¤šä¸ªè¯·æ±‚ï¼‰
	done   chan struct{} // ä¼˜é›…å…³é—­ä¿¡å·
}

// maskAPIKey å°†API Keyæ©ç ä¸º "abcd...klmn" æ ¼å¼ï¼ˆå‰4ä½ + ... + å4ä½ï¼‰
func maskAPIKey(key string) string {
	if len(key) <= 8 {
		return key // çŸ­keyç›´æ¥è¿”å›
	}
	return key[:4] + "..." + key[len(key)-4:]
}

// generateLogDBPath ä»ä¸»æ•°æ®åº“è·¯å¾„ç”Ÿæˆæ—¥å¿—æ•°æ®åº“è·¯å¾„
// ä¾‹å¦‚: ./data/ccload.db -> ./data/ccload-log.db
// ç‰¹æ®Šå¤„ç†: :memory: -> /tmp/ccload-test-log.dbï¼ˆæµ‹è¯•åœºæ™¯ï¼‰
func generateLogDBPath(mainDBPath string) string {
	// æ£€æµ‹ç‰¹æ®Šçš„å†…å­˜æ•°æ®åº“æ ‡è¯†ï¼ˆç”¨äºæµ‹è¯•ï¼‰
	if mainDBPath == ":memory:" {
		return filepath.Join(os.TempDir(), "ccload-test-log.db")
	}

	dir := filepath.Dir(mainDBPath)
	base := filepath.Base(mainDBPath)
	ext := filepath.Ext(base)
	name := strings.TrimSuffix(base, ext)
	return filepath.Join(dir, name+"-log"+ext)
}

// buildMainDBDSN æ„å»ºä¸»æ•°æ®åº“DSNï¼ˆæ”¯æŒå†…å­˜æ¨¡å¼ï¼‰
// å†…å­˜æ¨¡å¼ï¼šCCLOAD_USE_MEMORY_DB=true -> file:ccload_mem_db?mode=memory&cache=shared
// æ–‡ä»¶æ¨¡å¼ï¼šé»˜è®¤ -> file:/path/to/db?_pragma=...
//
// âš ï¸ é‡è¦ä¿®å¤ï¼ˆ2025-10-05ï¼‰ï¼š
// - ä½¿ç”¨å‘½åå†…å­˜æ•°æ®åº“ï¼ˆccload_mem_dbï¼‰è€ŒéåŒ¿åå†…å­˜æ•°æ®åº“ï¼ˆ::memory:ï¼‰
// - å‘½åæ•°æ®åº“çš„ç”Ÿå‘½å‘¨æœŸç»‘å®šåˆ°è¿›ç¨‹ï¼Œè€Œéæœ€åä¸€ä¸ªè¿æ¥
// - å³ä½¿æ‰€æœ‰è¿æ¥å…³é—­ï¼Œåªè¦è¿›ç¨‹å­˜æ´»ï¼Œæ•°æ®åº“å°±ä¿ç•™åœ¨å†…å­˜ä¸­
// - è§£å†³äº†è¿æ¥æ± ç”Ÿå‘½å‘¨æœŸå¯¼è‡´çš„"no such table"é”™è¯¯
func buildMainDBDSN(path string) string {
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"

	if useMemory {
		// å†…å­˜æ¨¡å¼ï¼šä½¿ç”¨å‘½åå†…å­˜æ•°æ®åº“ï¼ˆå…³é”®ä¿®å¤ï¼‰
		// mode=memory: æ˜¾å¼å£°æ˜ä¸ºå†…å­˜æ¨¡å¼
		// cache=shared: å¤šè¿æ¥å…±äº«åŒä¸€æ•°æ®åº“å®ä¾‹
		// âš¡ æ€§èƒ½ï¼šç§»é™¤WALï¼ˆå†…å­˜æ¨¡å¼ä¸éœ€è¦WALï¼‰
		return "file:ccload_mem_db?mode=memory&cache=shared&_pragma=busy_timeout(5000)&_foreign_keys=on&_loc=Local"
	}

	// æ–‡ä»¶æ¨¡å¼ï¼šä¿æŒåŸæœ‰é€»è¾‘
	return fmt.Sprintf("file:%s?_pragma=busy_timeout(5000)&_foreign_keys=on&_pragma=journal_mode=WAL&_loc=Local", path)
}

// buildLogDBDSN æ„å»ºæ—¥å¿—æ•°æ®åº“DSNï¼ˆå§‹ç»ˆä½¿ç”¨æ–‡ä»¶æ¨¡å¼ï¼‰
// æ—¥å¿—åº“ä¸ä½¿ç”¨å†…å­˜æ¨¡å¼ï¼Œç¡®ä¿æ•°æ®æŒä¹…æ€§
func buildLogDBDSN(path string) string {
	return fmt.Sprintf("file:%s?_pragma=busy_timeout(5000)&_pragma=journal_mode=WAL&_loc=Local", path)
}

func NewSQLiteStore(path string, redisSync *RedisSync) (*SQLiteStore, error) {
	// æ£€æŸ¥æ˜¯å¦å¯ç”¨å†…å­˜æ¨¡å¼
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"

	if !useMemory {
		// æ–‡ä»¶æ¨¡å¼ï¼šåˆ›å»ºæ•°æ®ç›®å½•ï¼ˆå†…å­˜æ¨¡å¼æ— éœ€åˆ›å»ºç›®å½•ï¼‰
		if err := os.MkdirAll(filepath.Dir(path), 0o755); err != nil {
			return nil, err
		}
	}

	// æ‰“å¼€ä¸»æ•°æ®åº“ï¼ˆchannels, cooldowns, rrï¼‰
	// ä½¿ç”¨æŠ½è±¡çš„DSNæ„å»ºå‡½æ•°ï¼Œæ”¯æŒå†…å­˜/æ–‡ä»¶æ¨¡å¼åˆ‡æ¢
	dsn := buildMainDBDSN(path)
	db, err := sql.Open("sqlite", dsn)
	if err != nil {
		return nil, err
	}
	db.SetMaxOpenConns(25)
	db.SetMaxIdleConns(5)

	// âš ï¸ å…³é”®ä¿®å¤ï¼ˆ2025-10-05ï¼‰ï¼šå†…å­˜æ¨¡å¼ä¸‹ç§»é™¤è¿æ¥ç”Ÿå‘½å‘¨æœŸé™åˆ¶
	// åŸå› ï¼šSetConnMaxLifetimeä¼šå¯¼è‡´æ‰€æœ‰è¿æ¥å®šæœŸè¿‡æœŸ
	//      å¦‚æœæ‰€æœ‰è¿æ¥åŒæ—¶å…³é—­ï¼Œå‘½åå†…å­˜æ•°æ®åº“ç†è®ºä¸Šä¸ä¼šé”€æ¯
	//      ä½†ä¸ºäº†ç»å¯¹å®‰å…¨ï¼Œå†…å­˜æ¨¡å¼ä¸‹è®©è¿æ¥æ°¸ä¸è¿‡æœŸ
	// æ–‡ä»¶æ¨¡å¼ï¼šä¿æŒ5åˆ†é’Ÿç”Ÿå‘½å‘¨æœŸï¼ˆé¿å…é•¿è¿æ¥ç§¯ç´¯èµ„æºæ³„æ¼ï¼‰
	if !useMemory {
		db.SetConnMaxLifetime(5 * time.Minute)
	}
	// å†…å­˜æ¨¡å¼ï¼šä¸è®¾ç½®ConnMaxLifetimeï¼Œè¿æ¥æ°¸ä¸è¿‡æœŸï¼ˆä¿è¯æ•°æ®åº“å§‹ç»ˆå¯ç”¨ï¼‰

	// æ‰“å¼€æ—¥å¿—æ•°æ®åº“ï¼ˆlogsï¼‰- å§‹ç»ˆä½¿ç”¨æ–‡ä»¶æ¨¡å¼
	logDBPath := generateLogDBPath(path)
	logDSN := buildLogDBDSN(logDBPath)
	logDB, err := sql.Open("sqlite", logDSN)
	if err != nil {
		_ = db.Close()
		return nil, fmt.Errorf("open log database: %w", err)
	}
	logDB.SetMaxOpenConns(10)
	logDB.SetMaxIdleConns(2)
	logDB.SetConnMaxLifetime(5 * time.Minute)

	s := &SQLiteStore{
		db:        db,
		logDB:     logDB,
		redisSync: redisSync,
		syncCh:    make(chan struct{}, 1), // ç¼“å†²åŒº=1ï¼Œå…è®¸ä¸€ä¸ªå¾…å¤„ç†ä»»åŠ¡
		done:      make(chan struct{}),
	}

	// âš ï¸ å†…å­˜æ•°æ®åº“å®ˆæŠ¤è¿æ¥ï¼ˆP0ä¿®å¤ 2025-10-05ï¼‰
	// SQLiteå†…å­˜æ•°æ®åº“çš„ç‰¹æ€§ï¼šå½“æœ€åä¸€ä¸ªè¿æ¥å…³é—­æ—¶ï¼Œæ•°æ®åº“è¢«åˆ é™¤
	// è§£å†³æ–¹æ¡ˆï¼šæŒæœ‰ä¸€ä¸ªæ°¸ä¸å…³é—­çš„"å®ˆæŠ¤è¿æ¥"ï¼Œç¡®ä¿æ•°æ®åº“å§‹ç»ˆå­˜åœ¨
	if useMemory {
		keeperConn, err := db.Conn(context.Background())
		if err != nil {
			_ = db.Close()
			_ = logDB.Close()
			return nil, fmt.Errorf("åˆ›å»ºå†…å­˜æ•°æ®åº“å®ˆæŠ¤è¿æ¥å¤±è´¥: %w", err)
		}
		s.keeperConn = keeperConn

		// å†…å­˜æ¨¡å¼æç¤ºä¿¡æ¯
		fmt.Println("âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šä¸»æ•°æ®åº“ä½¿ç”¨å†…å­˜æ¨¡å¼ï¼ˆCCLOAD_USE_MEMORY_DB=trueï¼‰")
		fmt.Println("   - ä½¿ç”¨å‘½åå†…å­˜æ•°æ®åº“ï¼ˆccload_mem_dbï¼‰+ å®ˆæŠ¤è¿æ¥æœºåˆ¶")
		fmt.Println("   - å®ˆæŠ¤è¿æ¥ç¡®ä¿æ•°æ®åº“ç”Ÿå‘½å‘¨æœŸç»‘å®šåˆ°æœåŠ¡è¿›ç¨‹")
		fmt.Println("   - è¿æ¥æ± æ— ç”Ÿå‘½å‘¨æœŸé™åˆ¶ï¼Œé˜²æ­¢è¿æ¥è¿‡æœŸå¯¼è‡´æ•°æ®åº“é”€æ¯")
		fmt.Println("   - æ¸ é“é…ç½®ã€å†·å´çŠ¶æ€ç­‰çƒ­æ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­")
		fmt.Println("   - æ—¥å¿—æ•°æ®ä»ç„¶æŒä¹…åŒ–åˆ°ç£ç›˜ï¼š", logDBPath)
		fmt.Println("   âš ï¸  è­¦å‘Šï¼šæœåŠ¡é‡å¯åä¸»æ•°æ®åº“æ•°æ®å°†ä¸¢å¤±ï¼Œè¯·é…ç½®RedisåŒæ­¥æˆ–é‡æ–°å¯¼å…¥CSV")
	}

	// è¿ç§»ä¸»æ•°æ®åº“è¡¨ç»“æ„
	if err := s.migrate(context.Background()); err != nil {
		_ = db.Close()
		_ = logDB.Close()
		return nil, err
	}

	// è¿ç§»æ—¥å¿—æ•°æ®åº“è¡¨ç»“æ„
	if err := s.migrateLogDB(context.Background()); err != nil {
		_ = db.Close()
		_ = logDB.Close()
		return nil, err
	}

	// å¯åŠ¨å¼‚æ­¥RedisåŒæ­¥workerï¼ˆä»…å½“Rediså¯ç”¨æ—¶ï¼‰
	if redisSync != nil && redisSync.IsEnabled() {
		go s.redisSyncWorker()
	}

	return s, nil
}

// migrate åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ï¼ˆUnixæ—¶é—´æˆ³åŸç”Ÿæ”¯æŒï¼‰
func (s *SQLiteStore) migrate(ctx context.Context) error {
	// åˆ›å»º channels è¡¨ï¼ˆcreated_at/updated_atä½¿ç”¨BIGINT Unixç§’æ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS channels (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			NAME TEXT NOT NULL,
			api_key TEXT NOT NULL,
			url TEXT NOT NULL,
			priority INTEGER NOT NULL DEFAULT 0,
			models TEXT NOT NULL,
			enabled INTEGER NOT NULL DEFAULT 1,
			created_at BIGINT NOT NULL,
			updated_at BIGINT NOT NULL
		);
	`); err != nil {
		return fmt.Errorf("create channels table: %w", err)
	}

	// åˆ›å»º cooldowns è¡¨ï¼ˆä½¿ç”¨Unixæ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS cooldowns (
			channel_id INTEGER PRIMARY KEY,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create cooldowns table: %w", err)
	}

	// æ·»åŠ æ–°å­—æ®µï¼ˆå…¼å®¹å·²æœ‰æ•°æ®åº“ï¼‰
	s.addColumnIfNotExists(ctx, "channels", "model_redirects", "TEXT DEFAULT '{}'")      // æ¨¡å‹é‡å®šå‘å­—æ®µï¼ŒJSONæ ¼å¼
	s.addColumnIfNotExists(ctx, "channels", "api_keys", "TEXT DEFAULT '[]'")             // å¤šKeyæ”¯æŒï¼ŒJSONæ•°ç»„
	s.addColumnIfNotExists(ctx, "channels", "key_strategy", "TEXT DEFAULT 'sequential'") // Keyä½¿ç”¨ç­–ç•¥
	s.addColumnIfNotExists(ctx, "channels", "channel_type", "TEXT DEFAULT 'anthropic'")  // æ¸ é“ç±»å‹

	// åˆ›å»º key_cooldowns è¡¨ï¼ˆKeyçº§åˆ«å†·å´ï¼Œä½¿ç”¨Unixæ—¶é—´æˆ³ï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS key_cooldowns (
			channel_id INTEGER NOT NULL,
			key_index INTEGER NOT NULL,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			PRIMARY KEY(channel_id, key_index),
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create key_cooldowns table: %w", err)
	}

	// åˆ›å»º key_rr è¡¨ï¼ˆKeyçº§åˆ«è½®è¯¢æŒ‡é’ˆï¼‰
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS key_rr (
			channel_id INTEGER PRIMARY KEY,
			idx INTEGER NOT NULL,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		);
	`); err != nil {
		return fmt.Errorf("create key_rr table: %w", err)
	}

	// åˆ›å»º rr (round-robin) è¡¨
	if _, err := s.db.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS rr (
			KEY TEXT PRIMARY KEY,
			idx INTEGER NOT NULL
		);
	`); err != nil {
		return fmt.Errorf("create rr table: %w", err)
	}

	// åˆ›å»ºæ¸ é“åç§°ç´¢å¼•
	if _, err := s.db.ExecContext(ctx, `
		CREATE INDEX IF NOT EXISTS idx_channels_name ON channels(NAME);
	`); err != nil {
		return fmt.Errorf("create channels name index: %w", err)
	}

	// ç¡®ä¿channelsè¡¨çš„nameå­—æ®µå…·æœ‰UNIQUEçº¦æŸ
	if err := s.ensureChannelNameUnique(ctx); err != nil {
		return fmt.Errorf("ensure channel name unique: %w", err)
	}

	// è¿ç§»api_keyså­—æ®µï¼šä¿®å¤å†å²æ•°æ®ä¸­çš„"null"å­—ç¬¦ä¸²é—®é¢˜
	if err := s.migrateAPIKeysField(ctx); err != nil {
		return fmt.Errorf("migrate api_keys field: %w", err)
	}

	// è¿ç§»å†·å´è¡¨çš„untilå­—æ®µä»TIMESTAMPåˆ°Unixæ—¶é—´æˆ³
	if err := s.migrateCooldownToUnixTimestamp(ctx); err != nil {
		return fmt.Errorf("migrate cooldown to unix timestamp: %w", err)
	}

	// Unixæ—¶é—´æˆ³é‡æ„ï¼šé‡å»ºè¡¨ç»“æ„ï¼ˆTIMESTAMP â†’ BIGINTï¼‰
	if err := s.rebuildChannelsTableToUnixTimestamp(ctx); err != nil {
		return fmt.Errorf("rebuild channels table: %w", err)
	}

	return nil
}

// migrateLogDB åˆ›å»ºæ—¥å¿—æ•°æ®åº“è¡¨ç»“æ„ï¼ˆç‹¬ç«‹æ•°æ®åº“ï¼Œä»é›¶å¼€å§‹ï¼Œæ— éœ€å…¼å®¹ï¼‰
func (s *SQLiteStore) migrateLogDB(ctx context.Context) error {
	// åˆ›å»º logs è¡¨ï¼ˆBIGINT Unixæ¯«ç§’æ—¶é—´æˆ³ï¼Œæ‰€æœ‰å­—æ®µä¸€æ¬¡æ€§åˆ›å»ºï¼‰
	// æ³¨æ„ï¼šæ—  FOREIGN KEY çº¦æŸï¼Œå› ä¸º channels è¡¨åœ¨ä¸»æ•°æ®åº“ä¸­
	if _, err := s.logDB.ExecContext(ctx, `
		CREATE TABLE IF NOT EXISTS logs (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			time BIGINT NOT NULL,
			model TEXT,
			channel_id INTEGER,
			status_code INTEGER NOT NULL,
			message TEXT,
			duration REAL,
			is_streaming INTEGER NOT NULL DEFAULT 0,
			first_byte_time REAL,
			api_key_used TEXT
		);
	`); err != nil {
		return fmt.Errorf("create logs table: %w", err)
	}

	// åˆ›å»ºç´¢å¼•ï¼ˆä¸€æ¬¡æ€§åˆ›å»ºï¼Œæ— éœ€å…¼å®¹æ£€æŸ¥ï¼‰
	indexes := []string{
		"CREATE INDEX IF NOT EXISTS idx_logs_time ON logs(time)",
		"CREATE INDEX IF NOT EXISTS idx_logs_status ON logs(status_code)",
		"CREATE INDEX IF NOT EXISTS idx_logs_time_model ON logs(time, model)",
		"CREATE INDEX IF NOT EXISTS idx_logs_time_channel ON logs(time, channel_id)",
		"CREATE INDEX IF NOT EXISTS idx_logs_time_status ON logs(time, status_code)",
	}

	for _, indexSQL := range indexes {
		if _, err := s.logDB.ExecContext(ctx, indexSQL); err != nil {
			return fmt.Errorf("create index: %w", err)
		}
	}

	return nil
}

// addColumnIfNotExists æ·»åŠ åˆ—å¦‚æœä¸å­˜åœ¨ï¼ˆç”¨äºæ•°æ®åº“å‡çº§å…¼å®¹ï¼‰
func (s *SQLiteStore) addColumnIfNotExists(ctx context.Context, tableName, columnName, columnDef string) {
	// æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
	query := fmt.Sprintf("PRAGMA table_info(%s)", tableName)
	rows, err := s.db.QueryContext(ctx, query)
	if err != nil {
		return
	}
	defer rows.Close()

	exists := false
	for rows.Next() {
		var cid int
		var name, dataType string
		var notNull, pk int
		var dfltValue sql.NullString

		if err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == columnName {
			exists = true
			break
		}
	}

	if !exists {
		alterQuery := fmt.Sprintf("ALTER TABLE %s ADD COLUMN %s %s", tableName, columnName, columnDef)
		s.db.ExecContext(ctx, alterQuery)
	}
}

// migrateAPIKeysField æ•°æ®åº“è¿ç§»ï¼šä¿®å¤api_keyså­—æ®µçš„è„æ•°æ®
// é—®é¢˜ï¼šå†å²æ•°æ®ä¸­api_keyså¯èƒ½å­˜å‚¨ä¸º"null"å­—ç¬¦ä¸²ï¼Œå¯¼è‡´GetAPIKeys()è¿”å›ç©ºæ•°ç»„
// è§£å†³æ–¹æ¡ˆï¼šå°†api_keyå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰è½¬æ¢ä¸ºapi_keys JSONæ•°ç»„
// æ‰§è¡Œæ—¶æœºï¼šæœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œï¼ˆåœ¨ensureChannelNameUniqueä¹‹åï¼‰
func (s *SQLiteStore) migrateAPIKeysField(ctx context.Context) error {
	// å†…å­˜æ•°æ®åº“æ¨¡å¼ï¼šè·³è¿‡å†å²æ•°æ®ä¿®å¤ï¼ˆKISSåŸåˆ™ï¼šå†…å­˜DBæ— å†å²æ•°æ®ï¼‰
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"
	if useMemory {
		return nil
	}

	// æŸ¥è¯¢æ‰€æœ‰éœ€è¦è¿ç§»çš„æ¸ é“ï¼šapi_keysä¸º"null"æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œä½†api_keyä¸ä¸ºç©º
	rows, err := s.db.QueryContext(ctx, `
		SELECT id, api_key
		FROM channels
		WHERE (api_keys IS NULL OR api_keys = 'null' OR api_keys = '' OR api_keys = '[]')
		  AND api_key IS NOT NULL
		  AND api_key != ''
	`)
	if err != nil {
		return fmt.Errorf("query channels for migration: %w", err)
	}
	defer rows.Close()

	migratedCount := 0
	for rows.Next() {
		var id int64
		var apiKey string
		if err := rows.Scan(&id, &apiKey); err != nil {
			continue // è·³è¿‡é”™è¯¯è¡Œ
		}

		// ä½¿ç”¨normalizeAPIKeysçš„ç›¸åŒé€»è¾‘ï¼šåˆ†å‰²api_keyå­—æ®µ
		keys := strings.Split(apiKey, ",")
		apiKeys := make([]string, 0, len(keys))
		for _, k := range keys {
			trimmed := strings.TrimSpace(k)
			if trimmed != "" {
				apiKeys = append(apiKeys, trimmed)
			}
		}

		// åºåˆ—åŒ–ä¸ºJSONæ•°ç»„
		apiKeysJSON, err := sonic.Marshal(apiKeys)
		if err != nil {
			continue // è·³è¿‡åºåˆ—åŒ–å¤±è´¥çš„
		}

		// æ›´æ–°æ•°æ®åº“
		_, err = s.db.ExecContext(ctx, `
			UPDATE channels
			SET api_keys = ?
			WHERE id = ?
		`, string(apiKeysJSON), id)
		if err == nil {
			migratedCount++
		}
	}

	if migratedCount > 0 {
		fmt.Printf("âœ… api_keyså­—æ®µè¿ç§»å®Œæˆï¼šä¿®å¤ %d æ¡æ¸ é“è®°å½•\n", migratedCount)
	}

	return nil
}

// ensureChannelNameUnique ç¡®ä¿channelsè¡¨çš„nameå­—æ®µå…·æœ‰UNIQUEçº¦æŸ
// ç®€åŒ–çš„å››æ­¥è¿ç§»æ–¹æ¡ˆï¼Œéµå¾ªKISSåŸåˆ™
func (s *SQLiteStore) ensureChannelNameUnique(ctx context.Context) error {
	// å†…å­˜æ•°æ®åº“æ¨¡å¼ä¼˜åŒ–ï¼šè·³è¿‡é‡å¤æ•°æ®æ£€æŸ¥ï¼Œç›´æ¥åˆ›å»ºç´¢å¼•ï¼ˆYAGNIï¼šå†…å­˜DBæ— å†å²é‡å¤æ•°æ®ï¼‰
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"
	if useMemory {
		// ç›´æ¥åˆ›å»ºUNIQUEç´¢å¼•ï¼ˆCREATE IF NOT EXISTSä¿è¯å¹‚ç­‰æ€§ï¼‰
		if _, err := s.db.ExecContext(ctx,
			"CREATE UNIQUE INDEX IF NOT EXISTS idx_channels_unique_name ON channels (NAME)",
		); err != nil {
			return fmt.Errorf("create unique index: %w", err)
		}
		return nil
	}

	// ç¬¬ä¸€æ­¥: åˆ é™¤æ—§çš„æ™®é€šç´¢å¼•
	if _, err := s.db.ExecContext(ctx, "DROP INDEX IF EXISTS idx_channels_name"); err != nil {
		return fmt.Errorf("drop old index: %w", err)
	}

	// ç¬¬äºŒæ­¥: æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨UNIQUEç´¢å¼•
	var count int
	err := s.db.QueryRowContext(ctx,
		"SELECT COUNT(*) FROM sqlite_master WHERE type = 'index' AND name = 'idx_channels_unique_name'",
	).Scan(&count)
	if err != nil {
		return fmt.Errorf("check unique index exists: %w", err)
	}
	if count > 0 {
		return nil // ç´¢å¼•å·²å­˜åœ¨ï¼Œé€€å‡º
	}

	// ç¬¬ä¸‰æ­¥: ä¿®å¤é‡å¤çš„nameæ•°æ®
	rows, err := s.db.QueryContext(ctx, `
		SELECT name, GROUP_CONCAT(id) AS ids
		FROM channels
		GROUP BY name
		HAVING COUNT(*) > 1
	`)
	if err != nil {
		return fmt.Errorf("find duplicates: %w", err)
	}
	defer rows.Close()

	duplicateCount := 0
	for rows.Next() {
		var name, idsStr string
		if err := rows.Scan(&name, &idsStr); err != nil {
			continue
		}

		ids := strings.Split(idsStr, ",")
		if len(ids) <= 1 {
			continue
		}

		duplicateCount++

		// ä¿ç•™ç¬¬ä¸€ä¸ªIDçš„nameä¸å˜ï¼Œå…¶ä»–IDçš„nameæ”¹ä¸º "åŸname+id"
		for i := 1; i < len(ids); i++ {
			newName := fmt.Sprintf("%s%s", name, ids[i])
			nowUnix := time.Now().Unix()
			_, err = s.db.ExecContext(ctx, `
				UPDATE channels SET name = ?, updated_at = ?
				WHERE id = ?
			`, newName, nowUnix, ids[i])
			if err != nil {
				return fmt.Errorf("fix duplicate name for id %s: %w", ids[i], err)
			}
		}
	}

	if duplicateCount > 0 {
		fmt.Printf("Fixed %d duplicate channel names\n", duplicateCount)
	}

	// ç¬¬å››æ­¥: åˆ›å»ºUNIQUEç´¢å¼•
	if _, err := s.db.ExecContext(ctx,
		"CREATE UNIQUE INDEX IF NOT EXISTS idx_channels_unique_name ON channels (NAME)",
	); err != nil {
		return fmt.Errorf("create unique index: %w", err)
	}

	return nil
}

// migrateCooldownToUnixTimestamp è¿ç§»å†·å´è¡¨çš„untilå­—æ®µä»TIMESTAMPåˆ°Unixæ—¶é—´æˆ³
// ç­–ç•¥ï¼šæ£€æµ‹å­—æ®µç±»å‹ï¼Œå¦‚æœæ˜¯TEXT/TIMESTAMPåˆ™é‡å»ºè¡¨ï¼Œå¦‚æœå·²ç»æ˜¯INTEGERåˆ™è·³è¿‡
func (s *SQLiteStore) migrateCooldownToUnixTimestamp(ctx context.Context) error {
	// å†…å­˜æ•°æ®åº“æ¨¡å¼ï¼šè·³è¿‡å†·å´è¡¨è¿ç§»ï¼ˆKISSåŸåˆ™ï¼šå†…å­˜DBå­—æ®µç±»å‹å·²æ­£ç¡®ï¼‰
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"
	if useMemory {
		return nil
	}

	// æ£€æŸ¥cooldownsè¡¨çš„untilå­—æ®µç±»å‹
	needMigrateCooldowns := false
	rows, err := s.db.QueryContext(ctx, "PRAGMA table_info(cooldowns)")
	if err != nil {
		return fmt.Errorf("check cooldowns table: %w", err)
	}
	for rows.Next() {
		var cid int
		var name, typ string
		var notnull, pk int
		var dfltValue any
		if err := rows.Scan(&cid, &name, &typ, &notnull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == "until" && typ != "INTEGER" {
			needMigrateCooldowns = true
			break
		}
	}
	rows.Close()

	if needMigrateCooldowns {
		// é‡å»ºcooldownsè¡¨
		if err := s.rebuildCooldownsTable(ctx); err != nil {
			return fmt.Errorf("rebuild cooldowns table: %w", err)
		}
		fmt.Println("âœ… è¿ç§» cooldowns è¡¨ï¼šTIMESTAMP â†’ Unixæ—¶é—´æˆ³")
	}

	// æ£€æŸ¥key_cooldownsè¡¨çš„untilå­—æ®µç±»å‹
	needMigrateKeyCooldowns := false
	rows, err = s.db.QueryContext(ctx, "PRAGMA table_info(key_cooldowns)")
	if err != nil {
		return fmt.Errorf("check key_cooldowns table: %w", err)
	}
	for rows.Next() {
		var cid int
		var name, typ string
		var notnull, pk int
		var dfltValue any
		if err := rows.Scan(&cid, &name, &typ, &notnull, &dfltValue, &pk); err != nil {
			continue
		}
		if name == "until" && typ != "INTEGER" {
			needMigrateKeyCooldowns = true
			break
		}
	}
	rows.Close()

	if needMigrateKeyCooldowns {
		// é‡å»ºkey_cooldownsè¡¨
		if err := s.rebuildKeyCooldownsTable(ctx); err != nil {
			return fmt.Errorf("rebuild key_cooldowns table: %w", err)
		}
		fmt.Println("âœ… è¿ç§» key_cooldowns è¡¨ï¼šTIMESTAMP â†’ Unixæ—¶é—´æˆ³")
	}

	return nil
}

// rebuildChannelsTableToUnixTimestamp é‡å»ºchannelsè¡¨ï¼Œå°†created_at/updated_atä»TIMESTAMPæ”¹ä¸ºBIGINTç§’
func (s *SQLiteStore) rebuildChannelsTableToUnixTimestamp(ctx context.Context) error {
	// å†…å­˜æ•°æ®åº“æ¨¡å¼ï¼šè·³è¿‡è¡¨é‡å»ºï¼ˆKISSåŸåˆ™ï¼šå†…å­˜DBæ€»æ˜¯å…¨æ–°çš„ï¼Œæ— éœ€å‘åå…¼å®¹è¿ç§»ï¼‰
	// åŸå› ï¼šå†…å­˜æ•°æ®åº“åœ¨å¯åŠ¨æ—¶å·²åˆ›å»ºæ­£ç¡®çš„BIGINTå­—æ®µç±»å‹ï¼Œé‡å»ºæ“ä½œä¸ä»…æ— å¿…è¦ï¼Œè¿˜å¼•å…¥ç«æ€æ¡ä»¶é£é™©
	useMemory := os.Getenv("CCLOAD_USE_MEMORY_DB") == "true"
	if useMemory {
		return nil // å†…å­˜æ¨¡å¼ç›´æ¥è·³è¿‡ï¼Œé¿å…DROP TABLEçš„å¹¶å‘ç«æ€çª—å£
	}

	// æ£€æŸ¥created_atå­—æ®µç±»å‹æ˜¯å¦éœ€è¦é‡å»º
	var fieldType string
	err := s.db.QueryRowContext(ctx, `
		SELECT type FROM pragma_table_info('channels') WHERE name = 'created_at'
	`).Scan(&fieldType)
	if err != nil {
		return nil // è¡¨ä¸å­˜åœ¨æˆ–å­—æ®µä¸å­˜åœ¨ï¼Œè·³è¿‡
	}

	// å¦‚æœå·²ç»æ˜¯INTEGER/BIGINTï¼Œè·³è¿‡é‡å»º
	if fieldType == "INTEGER" || fieldType == "BIGINT" {
		return nil
	}

	fmt.Println("ğŸ”„ é‡å»º channels è¡¨ï¼šcreated_at/updated_at(TIMESTAMP) â†’ (BIGINT ç§’)")

	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// 1. åˆ›å»ºæ–°è¡¨
	_, err = tx.ExecContext(ctx, `
		CREATE TABLE channels_new (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			name TEXT NOT NULL,
			api_key TEXT NOT NULL,
			api_keys TEXT DEFAULT '[]',
			key_strategy TEXT DEFAULT 'sequential',
			url TEXT NOT NULL,
			priority INTEGER NOT NULL DEFAULT 0,
			models TEXT NOT NULL,
			model_redirects TEXT DEFAULT '{}',
			channel_type TEXT DEFAULT 'anthropic',
			enabled INTEGER NOT NULL DEFAULT 1,
			created_at BIGINT NOT NULL,
			updated_at BIGINT NOT NULL
		)
	`)
	if err != nil {
		return fmt.Errorf("create new channels table: %w", err)
	}

	// 2. è¿ç§»æ•°æ®ï¼šè½¬æ¢TIMESTAMPä¸ºUnixç§’æ—¶é—´æˆ³
	_, err = tx.ExecContext(ctx, `
		INSERT INTO channels_new (id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		SELECT
			id,
			name,
			api_key,
			COALESCE(api_keys, '[]'),
			COALESCE(key_strategy, 'sequential'),
			url,
			priority,
			models,
			COALESCE(model_redirects, '{}'),
			COALESCE(channel_type, 'anthropic'),
			enabled,
			CAST(strftime('%s', substr(created_at, 1, 19)) AS INTEGER) as created_at,
			CAST(strftime('%s', substr(updated_at, 1, 19)) AS INTEGER) as updated_at
		FROM channels
	`)
	if err != nil {
		return fmt.Errorf("migrate channels data: %w", err)
	}

	// 3. åˆ é™¤æ—§è¡¨
	_, err = tx.ExecContext(ctx, `DROP TABLE channels`)
	if err != nil {
		return fmt.Errorf("drop old channels table: %w", err)
	}

	// 4. é‡å‘½åæ–°è¡¨
	_, err = tx.ExecContext(ctx, `ALTER TABLE channels_new RENAME TO channels`)
	if err != nil {
		return fmt.Errorf("rename channels table: %w", err)
	}

	// 5. é‡å»ºå”¯ä¸€ç´¢å¼•
	_, err = tx.ExecContext(ctx, `CREATE UNIQUE INDEX idx_channels_unique_name ON channels(name)`)
	if err != nil {
		return fmt.Errorf("create unique name index: %w", err)
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	fmt.Println("âœ… channels è¡¨é‡å»ºå®Œæˆ")
	return nil
}

// rebuildTimestampTable é€šç”¨è¡¨é‡å»ºå‡½æ•°ï¼Œç”¨äºTIMESTAMPåˆ°Unixæ—¶é—´æˆ³è¿ç§»
// éµå¾ªDRYåŸåˆ™ï¼Œæ¶ˆé™¤é‡å¤çš„è¡¨é‡å»ºé€»è¾‘
func (s *SQLiteStore) rebuildTimestampTable(ctx context.Context, tableName, createTableSQL string) error {
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	tempTableName := tableName + "_new"

	// 1. åˆ›å»ºä¸´æ—¶è¡¨ï¼ˆæ–°ç»“æ„ï¼‰
	createSQL := strings.ReplaceAll(createTableSQL, tableName, tempTableName)
	if _, err := tx.ExecContext(ctx, createSQL); err != nil {
		return fmt.Errorf("create temp table: %w", err)
	}

	// 2. æ¸…ç†æ—§æ•°æ®ï¼ˆTIMESTAMPæ ¼å¼æ— æ³•å¯é è½¬æ¢ï¼‰
	fmt.Printf("  æ¸…ç†æ—§çš„%sè®°å½•ï¼ˆæ ¼å¼ä¸å…¼å®¹ï¼‰\n", tableName)

	// 3. åˆ é™¤æ—§è¡¨
	dropSQL := fmt.Sprintf("DROP TABLE %s", tableName)
	if _, err := tx.ExecContext(ctx, dropSQL); err != nil {
		return fmt.Errorf("drop old table: %w", err)
	}

	// 4. é‡å‘½åæ–°è¡¨
	renameSQL := fmt.Sprintf("ALTER TABLE %s RENAME TO %s", tempTableName, tableName)
	if _, err := tx.ExecContext(ctx, renameSQL); err != nil {
		return fmt.Errorf("rename table: %w", err)
	}

	return tx.Commit()
}

// rebuildCooldownsTable é‡å»ºcooldownsè¡¨ï¼Œè¿ç§»ç°æœ‰æ•°æ®
func (s *SQLiteStore) rebuildCooldownsTable(ctx context.Context) error {
	createSQL := `
		CREATE TABLE cooldowns (
			channel_id INTEGER PRIMARY KEY,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		)
	`
	return s.rebuildTimestampTable(ctx, "cooldowns", createSQL)
}

// rebuildKeyCooldownsTable é‡å»ºkey_cooldownsè¡¨ï¼Œè¿ç§»ç°æœ‰æ•°æ®
func (s *SQLiteStore) rebuildKeyCooldownsTable(ctx context.Context) error {
	createSQL := `
		CREATE TABLE key_cooldowns (
			channel_id INTEGER NOT NULL,
			key_index INTEGER NOT NULL,
			until INTEGER NOT NULL,
			duration_ms INTEGER NOT NULL DEFAULT 0,
			PRIMARY KEY(channel_id, key_index),
			FOREIGN KEY(channel_id) REFERENCES channels(id) ON DELETE CASCADE
		)
	`
	return s.rebuildTimestampTable(ctx, "key_cooldowns", createSQL)
}

func (s *SQLiteStore) Close() error {
	// ä¼˜é›…å…³é—­ï¼šé€šçŸ¥workeré€€å‡º
	if s.done != nil {
		close(s.done)
	}

	// ç­‰å¾…workerå¤„ç†å®Œæœ€åçš„åŒæ­¥ä»»åŠ¡ï¼ˆæœ€å¤šç­‰å¾…100msï¼‰
	time.Sleep(100 * time.Millisecond)

	// âš ï¸ å†…å­˜æ•°æ®åº“å®ˆæŠ¤è¿æ¥ï¼šæœ€åå…³é—­ï¼ˆP0ä¿®å¤ 2025-10-05ï¼‰
	// ç¡®ä¿å®ˆæŠ¤è¿æ¥åœ¨æ‰€æœ‰å…¶ä»–æ“ä½œå®Œæˆåæ‰å…³é—­
	// è¿™æ ·å¯ä»¥ä¿è¯å†…å­˜æ•°æ®åº“åœ¨æ•´ä¸ªæœåŠ¡ç”Ÿå‘½å‘¨æœŸå†…å§‹ç»ˆå­˜åœ¨
	if s.keeperConn != nil {
		if err := s.keeperConn.Close(); err != nil {
			// è®°å½•é”™è¯¯ä½†ä¸å½±å“åç»­å…³é—­æ“ä½œ
			fmt.Printf("âš ï¸  å…³é—­å®ˆæŠ¤è¿æ¥å¤±è´¥: %v\n", err)
		}
	}

	// å…³é—­æ•°æ®åº“è¿æ¥æ± 
	if err := s.db.Close(); err != nil {
		return err
	}

	// å…³é—­æ—¥å¿—æ•°æ®åº“
	return s.logDB.Close()
}

// CleanupLogsBefore æ¸…ç†æˆªæ­¢æ—¶é—´ä¹‹å‰çš„æ—¥å¿—ï¼ˆDIPï¼šé€šè¿‡æ¥å£æš´éœ²ç»´æŠ¤æ“ä½œï¼‰
func (s *SQLiteStore) CleanupLogsBefore(ctx context.Context, cutoff time.Time) error {
	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³ï¼ˆä½¿ç”¨ logDBï¼‰
	cutoffMs := cutoff.UnixMilli()
	_, err := s.logDB.ExecContext(ctx, `DELETE FROM logs WHERE time < ?`, cutoffMs)
	return err
}

// ---- Store interface impl ----

func (s *SQLiteStore) ListConfigs(ctx context.Context) ([]*Config, error) {
	query := `
		SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		ORDER BY priority DESC, id ASC
	`
	rows, err := s.db.QueryContext(ctx, query)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰«æå™¨
	scanner := NewConfigScanner()
	return scanner.ScanConfigs(rows)
}

func (s *SQLiteStore) GetConfig(ctx context.Context, id int64) (*Config, error) {
	query := `
		SELECT id, name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at
		FROM channels
		WHERE id = ?
	`
	row := s.db.QueryRowContext(ctx, query, id)

	// ä½¿ç”¨ç»Ÿä¸€çš„æ‰«æå™¨
	scanner := NewConfigScanner()
	config, err := scanner.ScanConfig(row)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, errors.New("not found")
		}
		return nil, err
	}
	return config, nil
}

// GetEnabledChannelsByModel æŸ¥è¯¢æ”¯æŒæŒ‡å®šæ¨¡å‹çš„å¯ç”¨æ¸ é“ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨ LEFT JOIN ä¸€æ¬¡æ€§æŸ¥è¯¢æ¸ é“å’Œå†·å´çŠ¶æ€ï¼Œæ¶ˆé™¤ N+1 æŸ¥è¯¢é—®é¢˜
func (s *SQLiteStore) GetEnabledChannelsByModel(ctx context.Context, model string) ([]*Config, error) {
	var query string
	var args []any
	nowUnix := time.Now().Unix()

	if model == "*" {
		// é€šé…ç¬¦ï¼šè¿”å›æ‰€æœ‰å¯ç”¨ä¸”æœªå†·å´çš„æ¸ é“
		query = `
			SELECT c.id, c.name, c.api_key, c.api_keys, c.key_strategy, c.url, c.priority,
			       c.models, c.model_redirects, c.channel_type, c.enabled, c.created_at, c.updated_at
			FROM channels c
			LEFT JOIN cooldowns cd ON c.id = cd.channel_id
			WHERE c.enabled = 1
			  AND (cd.until IS NULL OR cd.until <= ?)
			ORDER BY c.priority DESC, c.id ASC
		`
		args = []any{nowUnix}
	} else {
		// ç²¾ç¡®åŒ¹é…ï¼šæŸ¥è¯¢æ”¯æŒè¯¥æ¨¡å‹ä¸”æœªå†·å´çš„æ¸ é“
		query = `
			SELECT c.id, c.name, c.api_key, c.api_keys, c.key_strategy, c.url, c.priority,
			       c.models, c.model_redirects, c.channel_type, c.enabled, c.created_at, c.updated_at
			FROM channels c
			LEFT JOIN cooldowns cd ON c.id = cd.channel_id
			WHERE c.enabled = 1
			  AND c.models LIKE ?
			  AND (cd.until IS NULL OR cd.until <= ?)
			ORDER BY c.priority DESC, c.id ASC
		`
		args = []any{"%" + model + "%", nowUnix}
	}

	rows, err := s.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	scanner := NewConfigScanner()
	return scanner.ScanConfigs(rows)
}

// GetEnabledChannelsByType æŸ¥è¯¢æŒ‡å®šç±»å‹çš„å¯ç”¨æ¸ é“ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨ LEFT JOIN ä¸€æ¬¡æ€§æŸ¥è¯¢æ¸ é“å’Œå†·å´çŠ¶æ€ï¼Œæ¶ˆé™¤ N+1 æŸ¥è¯¢é—®é¢˜
func (s *SQLiteStore) GetEnabledChannelsByType(ctx context.Context, channelType string) ([]*Config, error) {
	nowUnix := time.Now().Unix()
	query := `
		SELECT c.id, c.name, c.api_key, c.api_keys, c.key_strategy, c.url, c.priority,
		       c.models, c.model_redirects, c.channel_type, c.enabled, c.created_at, c.updated_at
		FROM channels c
		LEFT JOIN cooldowns cd ON c.id = cd.channel_id
		WHERE c.enabled = 1
		  AND c.channel_type = ?
		  AND (cd.until IS NULL OR cd.until <= ?)
		ORDER BY c.priority DESC, c.id ASC
	`

	rows, err := s.db.QueryContext(ctx, query, channelType, nowUnix)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	scanner := NewConfigScanner()
	return scanner.ScanConfigs(rows)
}

func (s *SQLiteStore) CreateConfig(ctx context.Context, c *Config) (*Config, error) {
	nowUnix := time.Now().Unix() // Unixç§’æ—¶é—´æˆ³
	modelsStr, _ := serializeModels(c.Models)
	modelRedirectsStr, _ := serializeModelRedirects(c.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(c)
	apiKeysStr, _ := sonic.Marshal(c.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„

	// ä½¿ç”¨GetChannelTypeç¡®ä¿é»˜è®¤å€¼
	channelType := c.GetChannelType()
	keyStrategy := c.GetKeyStrategy() // ç¡®ä¿é»˜è®¤å€¼

	res, err := s.db.ExecContext(ctx, `
		INSERT INTO channels(name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`, c.Name, c.APIKey, string(apiKeysStr), keyStrategy, c.URL, c.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(c.Enabled), nowUnix, nowUnix)

	if err != nil {
		return nil, err
	}
	id, _ := res.LastInsertId()

	// è·å–å®Œæ•´çš„é…ç½®ä¿¡æ¯
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return config, nil
}

func (s *SQLiteStore) UpdateConfig(ctx context.Context, id int64, upd *Config) (*Config, error) {
	if upd == nil {
		return nil, errors.New("update payload cannot be nil")
	}

	// ç¡®è®¤ç›®æ ‡å­˜åœ¨ï¼Œä¿æŒä¸ä¹‹å‰é€»è¾‘ä¸€è‡´
	if _, err := s.GetConfig(ctx, id); err != nil {
		return nil, err
	}

	name := strings.TrimSpace(upd.Name)
	apiKey := strings.TrimSpace(upd.APIKey)
	url := strings.TrimSpace(upd.URL)
	modelsStr, _ := serializeModels(upd.Models)
	modelRedirectsStr, _ := serializeModelRedirects(upd.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(upd)
	apiKeysStr, _ := sonic.Marshal(upd.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„
	channelType := upd.GetChannelType()         // ç¡®ä¿é»˜è®¤å€¼
	keyStrategy := upd.GetKeyStrategy()         // ç¡®ä¿é»˜è®¤å€¼
	updatedAtUnix := time.Now().Unix()          // Unixç§’æ—¶é—´æˆ³

	_, err := s.db.ExecContext(ctx, `
		UPDATE channels
		SET name=?, api_key=?, api_keys=?, key_strategy=?, url=?, priority=?, models=?, model_redirects=?, channel_type=?, enabled=?, updated_at=?
		WHERE id=?
	`, name, apiKey, string(apiKeysStr), keyStrategy, url, upd.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(upd.Enabled), updatedAtUnix, id)
	if err != nil {
		return nil, err
	}

	// è·å–æ›´æ–°åçš„é…ç½®
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return config, nil
}

func (s *SQLiteStore) ReplaceConfig(ctx context.Context, c *Config) (*Config, error) {
	nowUnix := time.Now().Unix() // Unixç§’æ—¶é—´æˆ³
	modelsStr, _ := serializeModels(c.Models)
	modelRedirectsStr, _ := serializeModelRedirects(c.ModelRedirects)

	// è§„èŒƒåŒ–APIKeyså­—æ®µï¼ˆDRYï¼šç»Ÿä¸€å¤„ç†ï¼Œé¿å…"null"å­—ç¬¦ä¸²ï¼‰
	normalizeAPIKeys(c)
	apiKeysStr, _ := sonic.Marshal(c.APIKeys) // åºåˆ—åŒ–å¤šKeyæ•°ç»„
	channelType := c.GetChannelType()         // ç¡®ä¿é»˜è®¤å€¼
	keyStrategy := c.GetKeyStrategy()         // ç¡®ä¿é»˜è®¤å€¼
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO channels(name, api_key, api_keys, key_strategy, url, priority, models, model_redirects, channel_type, enabled, created_at, updated_at)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		ON CONFLICT(NAME) DO UPDATE SET
			api_key = excluded.api_key,
			api_keys = excluded.api_keys,
			key_strategy = excluded.key_strategy,
			url = excluded.url,
			priority = excluded.priority,
			models = excluded.models,
			model_redirects = excluded.model_redirects,
			channel_type = excluded.channel_type,
			enabled = excluded.enabled,
			updated_at = excluded.updated_at
	`, c.Name, c.APIKey, string(apiKeysStr), keyStrategy, c.URL, c.Priority, modelsStr, modelRedirectsStr, channelType,
		boolToInt(c.Enabled), nowUnix, nowUnix)
	if err != nil {
		return nil, err
	}

	// è·å–å®é™…çš„è®°å½•IDï¼ˆå¯èƒ½æ˜¯æ–°åˆ›å»ºçš„æˆ–å·²å­˜åœ¨çš„ï¼‰
	var id int64
	err = s.db.QueryRowContext(ctx, `SELECT id FROM channels WHERE name = ?`, c.Name).Scan(&id)
	if err != nil {
		return nil, err
	}

	// è·å–å®Œæ•´çš„é…ç½®ä¿¡æ¯
	config, err := s.GetConfig(ctx, id)
	if err != nil {
		return nil, err
	}

	// æ³¨æ„: ReplaceConfigé€šå¸¸åœ¨æ‰¹é‡å¯¼å…¥æ—¶ä½¿ç”¨ï¼Œæœ€åä¼šç»Ÿä¸€è°ƒç”¨SyncAllChannelsToRedis
	// è¿™é‡Œä¸åšå•ç‹¬åŒæ­¥ï¼Œé¿å…CSVå¯¼å…¥æ—¶çš„Næ¬¡Redisæ“ä½œ

	return config, nil
}

func (s *SQLiteStore) DeleteConfig(ctx context.Context, id int64) error {
	// æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨ï¼ˆå¹‚ç­‰æ€§ï¼‰
	if _, err := s.GetConfig(ctx, id); err != nil {
		if strings.Contains(err.Error(), "not found") {
			return nil // è®°å½•ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
		}
		return err
	}

	// çº§è”åˆ é™¤æ‰€æœ‰å…³è”èµ„æºï¼ˆäº‹åŠ¡ä¿è¯åŸå­æ€§ï¼‰
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return fmt.Errorf("begin transaction: %w", err)
	}
	defer tx.Rollback()

	// 1. åˆ é™¤æ¸ é“é…ç½®
	if _, err := tx.ExecContext(ctx, `DELETE FROM channels WHERE id = ?`, id); err != nil {
		return fmt.Errorf("delete channel: %w", err)
	}

	// 2. çº§è”åˆ é™¤æ¸ é“çº§å†·å´æ•°æ®
	if _, err := tx.ExecContext(ctx, `DELETE FROM cooldowns WHERE channel_id = ?`, id); err != nil {
		return fmt.Errorf("delete cooldowns: %w", err)
	}

	// 3. çº§è”åˆ é™¤Keyçº§å†·å´æ•°æ®
	if _, err := tx.ExecContext(ctx, `DELETE FROM key_cooldowns WHERE channel_id = ?`, id); err != nil {
		return fmt.Errorf("delete key_cooldowns: %w", err)
	}

	// 4. çº§è”åˆ é™¤Keyè½®è¯¢æŒ‡é’ˆ
	if _, err := tx.ExecContext(ctx, `DELETE FROM key_rr WHERE channel_id = ?`, id); err != nil {
		return fmt.Errorf("delete key_rr: %w", err)
	}

	// æäº¤äº‹åŠ¡
	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	// å¼‚æ­¥å…¨é‡åŒæ­¥æ‰€æœ‰æ¸ é“åˆ°Redisï¼ˆéé˜»å¡ï¼Œç«‹å³è¿”å›ï¼‰
	s.triggerAsyncSync()

	return nil
}

func (s *SQLiteStore) GetCooldownUntil(ctx context.Context, configID int64) (time.Time, bool) {
	row := s.db.QueryRowContext(ctx, `SELECT until FROM cooldowns WHERE channel_id = ?`, configID)
	return scanUnixTimestamp(row)
}

// GetAllChannelCooldowns æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰æ¸ é“å†·å´çŠ¶æ€ï¼ˆP0æ€§èƒ½ä¼˜åŒ–ï¼‰
// æ€§èƒ½æå‡ï¼šNæ¬¡æŸ¥è¯¢ â†’ 1æ¬¡æŸ¥è¯¢ï¼Œæ¶ˆé™¤N+1é—®é¢˜
func (s *SQLiteStore) GetAllChannelCooldowns(ctx context.Context) (map[int64]time.Time, error) {
	now := time.Now().Unix()
	query := `SELECT channel_id, until FROM cooldowns WHERE until > ?`

	rows, err := s.db.QueryContext(ctx, query, now)
	if err != nil {
		return nil, fmt.Errorf("query all channel cooldowns: %w", err)
	}
	defer rows.Close()

	result := make(map[int64]time.Time)
	for rows.Next() {
		var channelID int64
		var until int64

		if err := rows.Scan(&channelID, &until); err != nil {
			return nil, fmt.Errorf("scan channel cooldown: %w", err)
		}

		result[channelID] = time.Unix(until, 0)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("iterate channel cooldowns: %w", err)
	}

	return result, nil
}

func (s *SQLiteStore) SetCooldown(ctx context.Context, configID int64, until time.Time) error {
	now := time.Now()
	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—å†·å´æŒç»­æ—¶é—´å’Œæ—¶é—´æˆ³
	durMs := calculateCooldownDuration(until, now)
	unixTime := toUnixTimestamp(until)

	_, err := s.db.ExecContext(ctx, `
		INSERT INTO cooldowns(channel_id, until, duration_ms) VALUES(?, ?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, unixTime, durMs)
	return err
}

// BumpCooldownOnError æŒ‡æ•°é€€é¿ï¼šé”™è¯¯ç¿»å€ï¼ˆè®¤è¯é”™è¯¯5åˆ†é’Ÿèµ·ï¼Œå…¶ä»–1ç§’èµ·ï¼Œæœ€å¤§30mï¼‰ï¼ŒæˆåŠŸæ¸…é›¶
func (s *SQLiteStore) BumpCooldownOnError(ctx context.Context, configID int64, now time.Time, statusCode int) (time.Duration, error) {
	var unixTime int64
	var durMs int64
	err := s.db.QueryRowContext(ctx, `
		SELECT until, COALESCE(duration_ms, 0)
		FROM cooldowns
		WHERE channel_id = ?
	`, configID).Scan(&unixTime, &durMs)

	if err != nil && !errors.Is(err, sql.ErrNoRows) {
		return 0, err
	}

	// ä»Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºtime.Time
	until := time.Unix(unixTime, 0)

	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´ï¼ˆä¼ é€’statusCodeç”¨äºç¡®å®šåˆå§‹å†·å´æ—¶é—´ï¼‰
	next := calculateBackoffDuration(durMs, until, now, &statusCode)

	newUntil := now.Add(next)
	// è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³å­˜å‚¨
	_, err = s.db.ExecContext(ctx, `
		INSERT INTO cooldowns(channel_id, until, duration_ms) VALUES(?, ?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, newUntil.Unix(), int64(next/time.Millisecond))

	if err != nil {
		return 0, err
	}
	return next, nil
}

func (s *SQLiteStore) ResetCooldown(ctx context.Context, configID int64) error {
	// åˆ é™¤è®°å½•ï¼Œç­‰æ•ˆäºå†·å´ä¸º0
	_, err := s.db.ExecContext(ctx, `DELETE FROM cooldowns WHERE channel_id = ?`, configID)
	return err
}

func (s *SQLiteStore) AddLog(ctx context.Context, e *LogEntry) error {
	if e.Time.Time.IsZero() {
		e.Time = JSONTime{time.Now()}
	}

	// æ¸…ç†å•è°ƒæ—¶é’Ÿä¿¡æ¯ï¼Œç¡®ä¿æ—¶é—´æ ¼å¼æ ‡å‡†åŒ–
	cleanTime := e.Time.Time.Round(0) // ç§»é™¤å•è°ƒæ—¶é’Ÿéƒ¨åˆ†

	// Unixæ—¶é—´æˆ³ï¼šç›´æ¥å­˜å‚¨æ¯«ç§’çº§Unixæ—¶é—´æˆ³
	timeMs := cleanTime.UnixMilli()

	// ç›´æ¥å†™å…¥æ—¥å¿—æ•°æ®åº“ï¼ˆç®€åŒ–é¢„ç¼–è¯‘è¯­å¥ç¼“å­˜ï¼‰
	query := `
		INSERT INTO logs(time, model, channel_id, status_code, message, duration, is_streaming, first_byte_time, api_key_used)
		VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)
	`

	_, err := s.logDB.ExecContext(ctx, query, timeMs, e.Model, e.ChannelID, e.StatusCode, e.Message, e.Duration, e.IsStreaming, e.FirstByteTime, e.APIKeyUsed)
	return err
}

func (s *SQLiteStore) ListLogs(ctx context.Context, since time.Time, limit, offset int, filter *LogFilter) ([]*LogEntry, error) {
	// ä½¿ç”¨æŸ¥è¯¢æ„å»ºå™¨æ„å»ºå¤æ‚æŸ¥è¯¢ï¼ˆä» logDB æŸ¥è¯¢ï¼‰
	// æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°æ¶ˆé™¤N+1é—®é¢˜ï¼ˆ100æ¸ é“åœºæ™¯æå‡50-100å€ï¼‰
	baseQuery := `
		SELECT id, time, model, channel_id, status_code, message, duration, is_streaming, first_byte_time, api_key_used
		FROM logs`

	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³ï¼Œéœ€è¦è½¬æ¢ä¸ºUnixæ¯«ç§’è¿›è¡Œæ¯”è¾ƒ
	sinceMs := since.UnixMilli()

    qb := NewQueryBuilder(baseQuery).
        Where("time >= ?", sinceMs)

    // æ”¯æŒæŒ‰æ¸ é“åç§°è¿‡æ»¤ï¼ˆæ— éœ€è·¨åº“JOINï¼Œå…ˆè§£æä¸ºæ¸ é“IDé›†åˆå†æŒ‰channel_idè¿‡æ»¤ï¼‰
    if filter != nil && (filter.ChannelName != "" || filter.ChannelNameLike != "") {
        ids, err := s.fetchChannelIDsByNameFilter(ctx, filter.ChannelName, filter.ChannelNameLike)
        if err != nil {
            return nil, err
        }
        if len(ids) == 0 {
            return []*LogEntry{}, nil
        }
        // è½¬æ¢ä¸º[]anyä»¥ç”¨äºå ä½ç¬¦
        vals := make([]any, 0, len(ids))
        for _, id := range ids {
            vals = append(vals, id)
        }
        qb.WhereIn("channel_id", vals)
    }

    // å…¶ä½™è¿‡æ»¤æ¡ä»¶ï¼ˆmodelç­‰ï¼‰
    qb.ApplyFilter(filter)

	suffix := "ORDER BY time DESC LIMIT ? OFFSET ?"
	query, args := qb.BuildWithSuffix(suffix)
	args = append(args, limit, offset)

	rows, err := s.logDB.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	out := []*LogEntry{}
	channelIDsToFetch := make(map[int64]bool)

	for rows.Next() {
		var e LogEntry
		var cfgID sql.NullInt64
		var duration sql.NullFloat64
		var isStreamingInt int
		var firstByteTime sql.NullFloat64
		var timeMs int64 // Unixæ¯«ç§’æ—¶é—´æˆ³
		var apiKeyUsed sql.NullString

		if err := rows.Scan(&e.ID, &timeMs, &e.Model, &cfgID,
			&e.StatusCode, &e.Message, &duration, &isStreamingInt, &firstByteTime, &apiKeyUsed); err != nil {
			return nil, err
		}

		// è½¬æ¢Unixæ¯«ç§’æ—¶é—´æˆ³ä¸ºtime.Time
		e.Time = JSONTime{time.UnixMilli(timeMs)}

		if cfgID.Valid {
			id := cfgID.Int64
			e.ChannelID = &id
			channelIDsToFetch[id] = true
		}
		if duration.Valid {
			e.Duration = duration.Float64
		}
		e.IsStreaming = isStreamingInt != 0
		if firstByteTime.Valid {
			fbt := firstByteTime.Float64
			e.FirstByteTime = &fbt
		}
		if apiKeyUsed.Valid && apiKeyUsed.String != "" {
			e.APIKeyUsed = maskAPIKey(apiKeyUsed.String)
		}
		out = append(out, &e)
	}

	// æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°ï¼ˆP0æ€§èƒ½ä¼˜åŒ–ï¼šN+1 â†’ 1æ¬¡æŸ¥è¯¢ï¼‰
	if len(channelIDsToFetch) > 0 {
		channelNames, err := s.fetchChannelNamesBatch(ctx, channelIDsToFetch)
		if err != nil {
			// é™çº§å¤„ç†ï¼šæŸ¥è¯¢å¤±è´¥ä¸å½±å“æ—¥å¿—è¿”å›ï¼Œä»…è®°å½•é”™è¯¯
			fmt.Printf("âš ï¸  æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°å¤±è´¥: %v\n", err)
			channelNames = make(map[int64]string)
		}

		// å¡«å……æ¸ é“åç§°
		for _, e := range out {
			if e.ChannelID != nil {
				if name, ok := channelNames[*e.ChannelID]; ok {
					e.ChannelName = name
				}
			}
		}
	}

	return out, nil
}

func (s *SQLiteStore) Aggregate(ctx context.Context, since time.Time, bucket time.Duration) ([]MetricPoint, error) {
	// æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨SQL GROUP BYè¿›è¡Œæ•°æ®åº“å±‚èšåˆï¼Œé¿å…å†…å­˜èšåˆ
	// åŸæ–¹æ¡ˆï¼šåŠ è½½æ‰€æœ‰æ—¥å¿—åˆ°å†…å­˜èšåˆï¼ˆ10ä¸‡æ¡æ—¥å¿—éœ€2-5ç§’ï¼Œå ç”¨100-200MBå†…å­˜ï¼‰
	// æ–°æ–¹æ¡ˆï¼šæ•°æ®åº“èšåˆï¼ˆæŸ¥è¯¢æ—¶é—´-80%ï¼Œå†…å­˜å ç”¨-90%ï¼‰
	// æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°æ¶ˆé™¤N+1é—®é¢˜ï¼ˆ100æ¸ é“åœºæ™¯æå‡50-100å€ï¼‰

	bucketSeconds := int64(bucket.Seconds())
	sinceUnix := since.Unix()

	// SQLèšåˆæŸ¥è¯¢ï¼šä½¿ç”¨Unixæ—¶é—´æˆ³é™¤æ³•å®ç°æ—¶é—´æ¡¶åˆ†ç»„ï¼ˆä» logDBï¼‰
	// æ€§èƒ½ä¼˜åŒ–ï¼štimeå­—æ®µä¸ºBIGINTæ¯«ç§’æ—¶é—´æˆ³ï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡10-100å€
	// bucket_ts = (unix_timestamp_seconds / bucket_seconds) * bucket_seconds
	query := `
		SELECT
			((time / 1000) / ?) * ? AS bucket_ts,
			channel_id,
			SUM(CASE WHEN status_code >= 200 AND status_code < 300 THEN 1 ELSE 0 END) AS success,
			SUM(CASE WHEN status_code < 200 OR status_code >= 300 THEN 1 ELSE 0 END) AS error
		FROM logs
		WHERE (time / 1000) >= ?
		GROUP BY bucket_ts, channel_id
		ORDER BY bucket_ts ASC
	`

	rows, err := s.logDB.QueryContext(ctx, query, bucketSeconds, bucketSeconds, sinceUnix)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	// è§£æèšåˆç»“æœï¼ŒæŒ‰æ—¶é—´æ¡¶é‡ç»„
	mapp := make(map[int64]*MetricPoint)
	channelIDsToFetch := make(map[int64]bool)

	for rows.Next() {
		var bucketTs int64
		var channelID sql.NullInt64
		var success, errorCount int

		if err := rows.Scan(&bucketTs, &channelID, &success, &errorCount); err != nil {
			return nil, err
		}

		// è·å–æˆ–åˆ›å»ºæ—¶é—´æ¡¶
		mp, ok := mapp[bucketTs]
		if !ok {
			mp = &MetricPoint{
				Ts:       time.Unix(bucketTs, 0),
				Channels: make(map[string]ChannelMetric),
			}
			mapp[bucketTs] = mp
		}

		// æ›´æ–°æ€»ä½“ç»Ÿè®¡
		mp.Success += success
		mp.Error += errorCount

		// æš‚æ—¶ä½¿ç”¨ channel_id ä½œä¸º keyï¼Œç¨åæ›¿æ¢ä¸º name
		channelKey := "æœªçŸ¥æ¸ é“"
		if channelID.Valid {
			channelKey = fmt.Sprintf("ch_%d", channelID.Int64)
			channelIDsToFetch[channelID.Int64] = true
		}

		mp.Channels[channelKey] = ChannelMetric{
			Success: success,
			Error:   errorCount,
		}
	}

	// æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°ï¼ˆP0æ€§èƒ½ä¼˜åŒ–ï¼šN+1 â†’ 1æ¬¡æŸ¥è¯¢ï¼‰
	channelNames := make(map[int64]string)
	if len(channelIDsToFetch) > 0 {
		var err error
		channelNames, err = s.fetchChannelNamesBatch(ctx, channelIDsToFetch)
		if err != nil {
			// é™çº§å¤„ç†ï¼šæŸ¥è¯¢å¤±è´¥ä¸å½±å“èšåˆè¿”å›ï¼Œä»…è®°å½•é”™è¯¯
			fmt.Printf("âš ï¸  æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°å¤±è´¥: %v\n", err)
			channelNames = make(map[int64]string)
		}
	}

	// æ›¿æ¢ channel_id ä¸º channel_name
	for _, mp := range mapp {
		newChannels := make(map[string]ChannelMetric)
		for key, metric := range mp.Channels {
			if key == "æœªçŸ¥æ¸ é“" {
				newChannels[key] = metric
			} else {
				// è§£æ ch_123 æ ¼å¼
				var channelID int64
				fmt.Sscanf(key, "ch_%d", &channelID)
				if name, ok := channelNames[channelID]; ok {
					newChannels[name] = metric
				} else {
					newChannels["æœªçŸ¥æ¸ é“"] = metric
				}
			}
		}
		mp.Channels = newChannels
	}

	// ç”Ÿæˆå®Œæ•´çš„æ—¶é—´åºåˆ—ï¼ˆå¡«å……ç©ºæ¡¶ï¼‰
	out := []MetricPoint{}
	now := time.Now()
	endTime := now.Truncate(bucket).Add(bucket)
	startTime := since.Truncate(bucket)

	for t := startTime; t.Before(endTime); t = t.Add(bucket) {
		ts := t.Unix()
		if mp, ok := mapp[ts]; ok {
			out = append(out, *mp)
		} else {
			out = append(out, MetricPoint{
				Ts:       t,
				Channels: make(map[string]ChannelMetric),
			})
		}
	}

	// å·²æŒ‰æ—¶é—´å‡åºï¼ˆGROUP BY bucket_ts ASCï¼‰
	return out, nil
}

func (s *SQLiteStore) NextRR(ctx context.Context, model string, priority int, n int) int {
	if n <= 0 {
		return 0
	}

	key := fmt.Sprintf("%s|%d", model, priority)
	tx, err := s.db.BeginTx(ctx, &sql.TxOptions{})
	if err != nil {
		return 0
	}
	defer func() { _ = tx.Rollback() }()

	var cur int
	err = tx.QueryRowContext(ctx, `SELECT idx FROM rr WHERE KEY = ?`, key).Scan(&cur)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			cur = 0
			if _, err := tx.ExecContext(ctx, `INSERT INTO rr(key, idx) VALUES(?, ?)`, key, 0); err != nil {
				return 0
			}
		} else {
			return 0
		}
	}

	if cur >= n {
		cur = 0
	}

	next := cur + 1
	if next >= n {
		next = 0
	}

	if _, err := tx.ExecContext(ctx, `UPDATE rr SET idx = ? WHERE KEY = ?`, next, key); err != nil {
		return cur
	}

	_ = tx.Commit()
	return cur
}

func (s *SQLiteStore) SetRR(ctx context.Context, model string, priority int, idx int) error {
	key := fmt.Sprintf("%s|%d", model, priority)
	_, err := s.db.ExecContext(ctx, `INSERT OR REPLACE INTO rr (key, idx) VALUES (?, ?)`, key, idx)
	return err
}

// GetStats å®ç°ç»Ÿè®¡åŠŸèƒ½ï¼ŒæŒ‰æ¸ é“å’Œæ¨¡å‹ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ¬¡æ•°ï¼ˆä» logDBï¼‰
// æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°æ¶ˆé™¤N+1é—®é¢˜ï¼ˆ100æ¸ é“åœºæ™¯æå‡50-100å€ï¼‰
func (s *SQLiteStore) GetStats(ctx context.Context, since time.Time, filter *LogFilter) ([]StatsEntry, error) {
	// ä½¿ç”¨æŸ¥è¯¢æ„å»ºå™¨æ„å»ºç»Ÿè®¡æŸ¥è¯¢ï¼ˆä» logDBï¼‰
	baseQuery := `
		SELECT
			channel_id,
			COALESCE(model, '') AS model,
			SUM(CASE WHEN status_code >= 200 AND status_code < 300 THEN 1 ELSE 0 END) AS success,
			SUM(CASE WHEN status_code < 200 OR status_code >= 300 THEN 1 ELSE 0 END) AS error,
			COUNT(*) AS total
		FROM logs`

	// timeå­—æ®µç°åœ¨æ˜¯BIGINTæ¯«ç§’æ—¶é—´æˆ³
	sinceMs := since.UnixMilli()

	qb := NewQueryBuilder(baseQuery).
		Where("time >= ?", sinceMs).
		ApplyFilter(filter)

	suffix := "GROUP BY channel_id, model ORDER BY channel_id ASC, model ASC"
	query, args := qb.BuildWithSuffix(suffix)

	rows, err := s.logDB.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var stats []StatsEntry
	channelIDsToFetch := make(map[int64]bool)

	for rows.Next() {
		var entry StatsEntry
		err := rows.Scan(&entry.ChannelID, &entry.Model,
			&entry.Success, &entry.Error, &entry.Total)
		if err != nil {
			return nil, err
		}

		if entry.ChannelID != nil {
			channelIDsToFetch[int64(*entry.ChannelID)] = true
		}
		stats = append(stats, entry)
	}

	// æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°ï¼ˆP0æ€§èƒ½ä¼˜åŒ–ï¼šN+1 â†’ 1æ¬¡æŸ¥è¯¢ï¼‰
	if len(channelIDsToFetch) > 0 {
		channelNames, err := s.fetchChannelNamesBatch(ctx, channelIDsToFetch)
		if err != nil {
			// é™çº§å¤„ç†ï¼šæŸ¥è¯¢å¤±è´¥ä¸å½±å“ç»Ÿè®¡è¿”å›ï¼Œä»…è®°å½•é”™è¯¯
			fmt.Printf("âš ï¸  æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°å¤±è´¥: %v\n", err)
			channelNames = make(map[int64]string)
		}

		// å¡«å……æ¸ é“åç§°
		for i := range stats {
			if stats[i].ChannelID != nil {
				if name, ok := channelNames[int64(*stats[i].ChannelID)]; ok {
					stats[i].ChannelName = name
				} else {
					stats[i].ChannelName = "ç³»ç»Ÿ"
				}
			} else {
				stats[i].ChannelName = "ç³»ç»Ÿ"
			}
		}
	} else {
		// æ²¡æœ‰æ¸ é“IDï¼Œå…¨éƒ¨æ ‡è®°ä¸ºç³»ç»Ÿ
		for i := range stats {
			stats[i].ChannelName = "ç³»ç»Ÿ"
		}
	}

	return stats, nil
}

// LoadChannelsFromRedis ä»Redisæ¢å¤æ¸ é“æ•°æ®åˆ°SQLite (å¯åŠ¨æ—¶æ•°æ®åº“æ¢å¤æœºåˆ¶)
func (s *SQLiteStore) LoadChannelsFromRedis(ctx context.Context) error {
	if !s.redisSync.IsEnabled() {
		return nil
	}

	// ä»RedisåŠ è½½æ‰€æœ‰æ¸ é“é…ç½®
	configs, err := s.redisSync.LoadChannelsFromRedis(ctx)
	if err != nil {
		return fmt.Errorf("load from redis: %w", err)
	}

	if len(configs) == 0 {
		fmt.Println("No channels found in Redis")
		return nil
	}

	fmt.Printf("Restoring %d channels from Redis...\n", len(configs))

	// ä½¿ç”¨äº‹åŠ¡ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ (ACIDåŸåˆ™)
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return fmt.Errorf("begin transaction: %w", err)
	}
	defer func() { _ = tx.Rollback() }()

	nowUnix := time.Now().Unix()
	successCount := 0

	for _, config := range configs {
		// æ ‡å‡†åŒ–æ•°æ®ï¼šç¡®ä¿é»˜è®¤å€¼æ­£ç¡®å¡«å……
		modelsStr, _ := serializeModels(config.Models)
		modelRedirectsStr, _ := serializeModelRedirects(config.ModelRedirects)
		apiKeysStr, _ := sonic.Marshal(config.APIKeys)
		channelType := config.GetChannelType() // å¼ºåˆ¶ä½¿ç”¨é»˜è®¤å€¼anthropic
		keyStrategy := config.GetKeyStrategy() // å¼ºåˆ¶ä½¿ç”¨é»˜è®¤å€¼sequential

		// ä½¿ç”¨å®Œæ•´å­—æ®µåˆ—è¡¨ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼ˆåŒ…å«æ‰€æœ‰æ–°å­—æ®µï¼‰
		_, err := tx.ExecContext(ctx, `
			INSERT OR REPLACE INTO channels(
				name, api_key, api_keys, key_strategy, url, priority,
				models, model_redirects, channel_type, enabled, created_at, updated_at
			)
			VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
		`, config.Name, config.APIKey, string(apiKeysStr), keyStrategy, config.URL, config.Priority,
			modelsStr, modelRedirectsStr, channelType, boolToInt(config.Enabled), nowUnix, nowUnix)

		if err != nil {
			fmt.Printf("Warning: failed to restore channel %s: %v\n", config.Name, err)
			continue
		}
		successCount++
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("commit transaction: %w", err)
	}

	fmt.Printf("Successfully restored %d/%d channels from Redis\n", successCount, len(configs))
	return nil
}

// SyncAllChannelsToRedis å°†æ‰€æœ‰æ¸ é“åŒæ­¥åˆ°Redis (æ‰¹é‡åŒæ­¥ï¼Œåˆå§‹åŒ–æ—¶ä½¿ç”¨)
func (s *SQLiteStore) SyncAllChannelsToRedis(ctx context.Context) error {
	if !s.redisSync.IsEnabled() {
		return nil
	}

	configs, err := s.ListConfigs(ctx)
	if err != nil {
		return fmt.Errorf("list configs: %w", err)
	}

	if len(configs) == 0 {
		fmt.Println("No channels to sync to Redis")
		return nil
	}

	// è§„èŒƒåŒ–æ‰€æœ‰Configå¯¹è±¡çš„é»˜è®¤å€¼ï¼ˆç¡®ä¿Redisä¸­æ•°æ®å®Œæ•´æ€§ï¼‰
	normalizeConfigDefaults(configs)

	fmt.Printf("Syncing %d channels to Redis...\n", len(configs))

	if err := s.redisSync.SyncAllChannels(ctx, configs); err != nil {
		return fmt.Errorf("sync to redis: %w", err)
	}

	fmt.Printf("Successfully synced %d channels to Redis\n", len(configs))
	return nil
}

// redisSyncWorker å¼‚æ­¥RedisåŒæ­¥workerï¼ˆåå°goroutineï¼‰
// ä¿®å¤ï¼šå¢åŠ é‡è¯•æœºåˆ¶ï¼Œé¿å…ç¬æ—¶ç½‘ç»œæ•…éšœå¯¼è‡´æ•°æ®ä¸¢å¤±ï¼ˆP0ä¿®å¤ 2025-10-05ï¼‰
func (s *SQLiteStore) redisSyncWorker() {
	ctx := context.Background()

	// æŒ‡æ•°é€€é¿é‡è¯•é…ç½®
	retryBackoff := []time.Duration{
		1 * time.Second,   // ç¬¬1æ¬¡é‡è¯•ï¼š1ç§’å
		5 * time.Second,   // ç¬¬2æ¬¡é‡è¯•ï¼š5ç§’å
		15 * time.Second,  // ç¬¬3æ¬¡é‡è¯•ï¼š15ç§’å
	}

	for {
		select {
		case <-s.syncCh:
			// æ‰§è¡ŒåŒæ­¥æ“ä½œï¼Œæ”¯æŒé‡è¯•
			syncErr := s.doSyncAllChannelsWithRetry(ctx, retryBackoff)
			if syncErr != nil {
				// æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè®°å½•è‡´å‘½é”™è¯¯
				fmt.Printf("âŒ ä¸¥é‡é”™è¯¯: RedisåŒæ­¥å¤±è´¥ï¼ˆå·²é‡è¯•%dæ¬¡ï¼‰: %v\n", len(retryBackoff), syncErr)
				fmt.Printf("   è­¦å‘Š: æœåŠ¡é‡å¯åå¯èƒ½ä¸¢å¤±æ¸ é“é…ç½®ï¼Œè¯·æ£€æŸ¥Redisè¿æ¥æˆ–æ‰‹åŠ¨å¤‡ä»½æ•°æ®åº“\n")
			}

		case <-s.done:
			// ä¼˜é›…å…³é—­ï¼šå¤„ç†å®Œæœ€åä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
			select {
			case <-s.syncCh:
				// å…³é—­æ—¶ä¸é‡è¯•ï¼Œå¿«é€ŸåŒæ­¥ä¸€æ¬¡å³å¯
				_ = s.doSyncAllChannels(ctx)
			default:
			}
			return
		}
	}
}

// doSyncAllChannelsWithRetry å¸¦é‡è¯•æœºåˆ¶çš„åŒæ­¥æ“ä½œï¼ˆP0ä¿®å¤æ–°å¢ï¼‰
func (s *SQLiteStore) doSyncAllChannelsWithRetry(ctx context.Context, retryBackoff []time.Duration) error {
	var lastErr error

	// é¦–æ¬¡å°è¯•
	if err := s.doSyncAllChannels(ctx); err == nil {
		return nil // æˆåŠŸ
	} else {
		lastErr = err
		fmt.Printf("âš ï¸  RedisåŒæ­¥å¤±è´¥ï¼ˆå°†è‡ªåŠ¨é‡è¯•ï¼‰: %v\n", err)
	}

	// é‡è¯•é€»è¾‘
	for attempt := 0; attempt < len(retryBackoff); attempt++ {
		// ç­‰å¾…é€€é¿æ—¶é—´
		time.Sleep(retryBackoff[attempt])

		// é‡è¯•åŒæ­¥
		if err := s.doSyncAllChannels(ctx); err == nil {
			fmt.Printf("âœ… RedisåŒæ­¥æ¢å¤æˆåŠŸï¼ˆç¬¬%dæ¬¡é‡è¯•ï¼‰\n", attempt+1)
			return nil // æˆåŠŸ
		} else {
			lastErr = err
			fmt.Printf("âš ï¸  RedisåŒæ­¥é‡è¯•å¤±è´¥ï¼ˆç¬¬%dæ¬¡ï¼‰: %v\n", attempt+1, err)
		}
	}

	// æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
	return fmt.Errorf("all %d retries failed: %w", len(retryBackoff), lastErr)
}

// triggerAsyncSync è§¦å‘å¼‚æ­¥RedisåŒæ­¥ï¼ˆéé˜»å¡ï¼‰
func (s *SQLiteStore) triggerAsyncSync() {
	if s.redisSync == nil || !s.redisSync.IsEnabled() {
		return
	}

	// éé˜»å¡å‘é€ï¼ˆå¦‚æœchannelå·²æ»¡åˆ™è·³è¿‡ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹ï¼‰
	select {
	case s.syncCh <- struct{}{}:
		// æˆåŠŸå‘é€ä¿¡å·
	default:
		// channelå·²æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œè·³è¿‡ï¼ˆå»é‡ï¼‰
	}
}

// doSyncAllChannels å®é™…æ‰§è¡ŒåŒæ­¥æ“ä½œï¼ˆworkerå†…éƒ¨è°ƒç”¨ï¼‰
func (s *SQLiteStore) doSyncAllChannels(ctx context.Context) error {
	configs, err := s.ListConfigs(ctx)
	if err != nil {
		return fmt.Errorf("list configs: %w", err)
	}

	// è§„èŒƒåŒ–é»˜è®¤å€¼åå†åŒæ­¥ï¼ˆä¸SyncAllChannelsToRedisä¿æŒä¸€è‡´ï¼‰
	normalizeConfigDefaults(configs)

	return s.redisSync.SyncAllChannels(ctx, configs)
}

// normalizeConfigDefaults è§„èŒƒåŒ–Configå¯¹è±¡çš„é»˜è®¤å€¼å­—æ®µï¼ˆDRYåŸåˆ™ï¼šç»Ÿä¸€è§„èŒƒåŒ–é€»è¾‘ï¼‰
// ç¡®ä¿åºåˆ—åŒ–åˆ°Redisæ—¶æ‰€æœ‰å­—æ®µéƒ½æœ‰æ­£ç¡®çš„é»˜è®¤å€¼ï¼Œé¿å…ç©ºå€¼æ±¡æŸ“
func normalizeConfigDefaults(configs []*Config) {
	for _, config := range configs {
		// å¼ºåˆ¶å¡«å……channel_typeé»˜è®¤å€¼ï¼ˆé¿å…ç©ºå­—ç¬¦ä¸²åºåˆ—åŒ–åˆ°Redisï¼‰
		if config.ChannelType == "" {
			config.ChannelType = "anthropic"
		}
		// å¼ºåˆ¶å¡«å……key_strategyé»˜è®¤å€¼
		if config.KeyStrategy == "" {
			config.KeyStrategy = "sequential"
		}
		// ç¡®ä¿model_redirectsä¸ä¸ºnilï¼ˆé¿å…åºåˆ—åŒ–ä¸ºnullï¼‰
		if config.ModelRedirects == nil {
			config.ModelRedirects = make(map[string]string)
		}
		// ç¡®ä¿api_keysä¸ä¸ºnil
		if config.APIKeys == nil {
			config.APIKeys = []string{}
		}
	}
}

// fetchChannelNamesBatch æ‰¹é‡æŸ¥è¯¢æ¸ é“åç§°ï¼ˆP0æ€§èƒ½ä¼˜åŒ– 2025-10-05ï¼‰
// æ€§èƒ½æå‡ï¼šN+1æŸ¥è¯¢ â†’ 1æ¬¡å…¨è¡¨æŸ¥è¯¢ + å†…å­˜è¿‡æ»¤ï¼ˆ100æ¸ é“åœºæ™¯æå‡50-100å€ï¼‰
// è®¾è®¡åŸåˆ™ï¼ˆKISSï¼‰ï¼šæ¸ é“æ€»æ•°<1000ï¼Œå…¨è¡¨æ‰«ææ¯”INå­æŸ¥è¯¢æ›´ç®€å•ã€æ›´å¿«
// è¾“å…¥ï¼šæ¸ é“IDé›†åˆ map[int64]bool
// è¾“å‡ºï¼šIDâ†’åç§°æ˜ å°„ map[int64]string
func (s *SQLiteStore) fetchChannelNamesBatch(ctx context.Context, channelIDs map[int64]bool) (map[int64]string, error) {
	if len(channelIDs) == 0 {
		return make(map[int64]string), nil
	}

	// æŸ¥è¯¢æ‰€æœ‰æ¸ é“ï¼ˆå…¨è¡¨æ‰«æï¼Œæ¸ é“æ•°<1000æ—¶æ¯”INå­æŸ¥è¯¢æ›´å¿«ï¼‰
	// ä¼˜åŠ¿ï¼šå›ºå®šSQLï¼ˆæŸ¥è¯¢è®¡åˆ’ç¼“å­˜ï¼‰ã€æ— åŠ¨æ€å‚æ•°ç»‘å®šã€ä»£ç ç®€å•
	rows, err := s.db.QueryContext(ctx, "SELECT id, name FROM channels")
	if err != nil {
		return nil, fmt.Errorf("query all channel names: %w", err)
	}
	defer rows.Close()

	// è§£æå¹¶è¿‡æ»¤éœ€è¦çš„æ¸ é“ï¼ˆå†…å­˜è¿‡æ»¤ï¼ŒO(N)ä½†N<1000ï¼‰
	channelNames := make(map[int64]string, len(channelIDs))
	for rows.Next() {
		var id int64
		var name string
		if err := rows.Scan(&id, &name); err != nil {
			continue // è·³è¿‡æ‰«æé”™è¯¯çš„è¡Œ
		}
		// åªä¿ç•™éœ€è¦çš„æ¸ é“
		if channelIDs[id] {
			channelNames[id] = name
		}
	}

	return channelNames, nil
}

// fetchChannelIDsByNameFilter æ ¹æ®ç²¾ç¡®/æ¨¡ç³Šåç§°è·å–æ¸ é“IDé›†åˆ
// ç›®çš„ï¼šé¿å…è·¨åº“JOINï¼ˆlogsåœ¨logDBï¼Œchannelsåœ¨ä¸»dbï¼‰ï¼Œå…ˆè§£æä¸ºIDå†è¿‡æ»¤logs
func (s *SQLiteStore) fetchChannelIDsByNameFilter(ctx context.Context, exact string, like string) ([]int64, error) {
    // æ„å»ºæŸ¥è¯¢
    var (
        query string
        args  []any
    )
    if exact != "" {
        query = "SELECT id FROM channels WHERE name = ?"
        args = []any{exact}
    } else if like != "" {
        query = "SELECT id FROM channels WHERE name LIKE ?"
        args = []any{"%" + like + "%"}
    } else {
        return nil, nil
    }

    rows, err := s.db.QueryContext(ctx, query, args...)
    if err != nil {
        return nil, fmt.Errorf("query channel ids by name: %w", err)
    }
    defer rows.Close()

    var ids []int64
    for rows.Next() {
        var id int64
        if err := rows.Scan(&id); err != nil {
            return nil, fmt.Errorf("scan channel id: %w", err)
        }
        ids = append(ids, id)
    }
    if err := rows.Err(); err != nil {
        return nil, err
    }
    return ids, nil
}

// CheckDatabaseExists æ£€æŸ¥SQLiteæ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
func CheckDatabaseExists(dbPath string) bool {
	if _, err := os.Stat(dbPath); err != nil {
		return false
	}
	return true
}

// è¾…åŠ©å‡½æ•°
func boolToInt(b bool) int {
	if b {
		return 1
	}
	return 0
}

// ==================== Keyçº§åˆ«å†·å´æœºåˆ¶ ====================

// GetKeyCooldownUntil æŸ¥è¯¢æŒ‡å®šKeyçš„å†·å´æˆªæ­¢æ—¶é—´
func (s *SQLiteStore) GetKeyCooldownUntil(ctx context.Context, configID int64, keyIndex int) (time.Time, bool) {
	row := s.db.QueryRowContext(ctx, `
		SELECT until FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex)
	return scanUnixTimestamp(row)
}

// GetAllKeyCooldowns æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰Keyå†·å´çŠ¶æ€ï¼ˆP1ä¿®å¤ 2025-10-05ï¼‰
// è¿”å›: map[channelID]map[keyIndex]cooldownUntil
// æ€§èƒ½ä¼˜åŒ–: ä¸€æ¬¡æŸ¥è¯¢æ›¿ä»£ N*M æ¬¡ç‹¬ç«‹æŸ¥è¯¢ï¼ˆN=æ¸ é“æ•°, M=Keyæ•°ï¼‰
func (s *SQLiteStore) GetAllKeyCooldowns(ctx context.Context) (map[int64]map[int]time.Time, error) {
	now := time.Now().Unix()
	query := `SELECT channel_id, key_index, until FROM key_cooldowns WHERE until > ?`

	rows, err := s.db.QueryContext(ctx, query, now)
	if err != nil {
		return nil, fmt.Errorf("query all key cooldowns: %w", err)
	}
	defer rows.Close()

	result := make(map[int64]map[int]time.Time)
	for rows.Next() {
		var channelID int64
		var keyIndex int
		var until int64

		if err := rows.Scan(&channelID, &keyIndex, &until); err != nil {
			return nil, fmt.Errorf("scan key cooldown: %w", err)
		}

		// åˆå§‹åŒ–æ¸ é“çº§map
		if result[channelID] == nil {
			result[channelID] = make(map[int]time.Time)
		}
		result[channelID][keyIndex] = time.Unix(until, 0)
	}

	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("rows error: %w", err)
	}

	return result, nil
}

// BumpKeyCooldownOnError Keyçº§åˆ«æŒ‡æ•°é€€é¿ï¼šé”™è¯¯ç¿»å€ï¼ˆè®¤è¯é”™è¯¯5åˆ†é’Ÿèµ·ï¼Œå…¶ä»–1ç§’èµ·ï¼Œæœ€å¤§30mï¼‰
func (s *SQLiteStore) BumpKeyCooldownOnError(ctx context.Context, configID int64, keyIndex int, now time.Time, statusCode int) (time.Duration, error) {
	var unixTime int64
	var durMs int64
	err := s.db.QueryRowContext(ctx, `
		SELECT until, COALESCE(duration_ms, 0)
		FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex).Scan(&unixTime, &durMs)

	if err != nil && !errors.Is(err, sql.ErrNoRows) {
		return 0, err
	}

	// ä»Unixæ—¶é—´æˆ³è½¬æ¢ä¸ºtime.Time
	until := time.Unix(unixTime, 0)

	// ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´ï¼ˆä¼ é€’statusCodeç”¨äºç¡®å®šåˆå§‹å†·å´æ—¶é—´ï¼‰
	next := calculateBackoffDuration(durMs, until, now, &statusCode)

	newUntil := now.Add(next)
	// è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³å­˜å‚¨
	_, err = s.db.ExecContext(ctx, `
		INSERT INTO key_cooldowns(channel_id, key_index, until, duration_ms) VALUES(?, ?, ?, ?)
		ON CONFLICT(channel_id, key_index) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, keyIndex, newUntil.Unix(), int64(next/time.Millisecond))

	if err != nil {
		return 0, err
	}
	return next, nil
}

// SetKeyCooldown è®¾ç½®æŒ‡å®šKeyçš„å†·å´æˆªæ­¢æ—¶é—´
func (s *SQLiteStore) SetKeyCooldown(ctx context.Context, configID int64, keyIndex int, until time.Time) error {
	now := time.Now()
	durationMs := calculateCooldownDuration(until, now)
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO key_cooldowns(channel_id, key_index, until, duration_ms) VALUES(?, ?, ?, ?)
		ON CONFLICT(channel_id, key_index) DO UPDATE SET
			until = excluded.until,
			duration_ms = excluded.duration_ms
	`, configID, keyIndex, until.Unix(), durationMs)
	return err
}

// ResetKeyCooldown é‡ç½®æŒ‡å®šKeyçš„å†·å´çŠ¶æ€
func (s *SQLiteStore) ResetKeyCooldown(ctx context.Context, configID int64, keyIndex int) error {
	_, err := s.db.ExecContext(ctx, `
		DELETE FROM key_cooldowns
		WHERE channel_id = ? AND key_index = ?
	`, configID, keyIndex)
	return err
}

// ClearAllKeyCooldowns æ¸…ç†æ¸ é“çš„æ‰€æœ‰Keyå†·å´æ•°æ®ï¼ˆç”¨äºKeyå˜æ›´æ—¶é¿å…ç´¢å¼•é”™ä½ï¼‰
func (s *SQLiteStore) ClearAllKeyCooldowns(ctx context.Context, configID int64) error {
	_, err := s.db.ExecContext(ctx, `
		DELETE FROM key_cooldowns
		WHERE channel_id = ?
	`, configID)
	return err
}

// ==================== Keyçº§åˆ«è½®è¯¢æœºåˆ¶ ====================

// NextKeyRR è·å–ä¸‹ä¸€ä¸ªè½®è¯¢Keyç´¢å¼•ï¼ˆå¸¦è‡ªåŠ¨å¢é‡ï¼‰
func (s *SQLiteStore) NextKeyRR(ctx context.Context, configID int64, keyCount int) int {
	if keyCount <= 0 {
		return 0
	}

	var idx int
	err := s.db.QueryRowContext(ctx, `
		SELECT idx FROM key_rr WHERE channel_id = ?
	`, configID).Scan(&idx)

	if err != nil {
		// æ²¡æœ‰è®°å½•ï¼Œä»0å¼€å§‹
		return 0
	}

	// ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
	return idx % keyCount
}

// SetKeyRR è®¾ç½®æ¸ é“çš„Keyè½®è¯¢æŒ‡é’ˆ
func (s *SQLiteStore) SetKeyRR(ctx context.Context, configID int64, idx int) error {
	_, err := s.db.ExecContext(ctx, `
		INSERT INTO key_rr(channel_id, idx) VALUES(?, ?)
		ON CONFLICT(channel_id) DO UPDATE SET idx = excluded.idx
	`, configID, idx)
	return err
}
